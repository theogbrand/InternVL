{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports completed successfully\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import uuid\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"Imports completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from full_dvqa_en_20240402_extracted_int_only.jsonl...\n",
      "Loaded 20442 records\n",
      "Sample record: {'image': 'MMPR-v1.2-prompts/correctness_images/dvqa_en_20240402_extracted_int_only/images/bar_train_00109559.png', 'question': 'What is the value of the largest individual bar in the whole chart? Answer the question using a single word or phrase.', 'answer': '6'}\n"
     ]
    }
   ],
   "source": [
    "# Load the full JSONL file\n",
    "input_file = \"full_dvqa_en_20240402_extracted_int_only.jsonl\"\n",
    "data = []\n",
    "\n",
    "print(f\"Loading data from {input_file}...\")\n",
    "with open(input_file, 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line.strip()))\n",
    "\n",
    "print(f\"Loaded {len(data)} records\")\n",
    "print(\"Sample record:\", data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19609 unique images\n",
      "Selected 15000 records for subset\n"
     ]
    }
   ],
   "source": [
    "# Group by unique images to ensure no duplicates\n",
    "unique_images = {}\n",
    "for record in data:\n",
    "    image_path = record[\"image\"]\n",
    "    if image_path not in unique_images:\n",
    "        unique_images[image_path] = record\n",
    "\n",
    "print(f\"Found {len(unique_images)} unique images\")\n",
    "\n",
    "# Sample 15K unique records\n",
    "sample_size = 15000\n",
    "unique_records = list(unique_images.values())\n",
    "\n",
    "if len(unique_records) < sample_size:\n",
    "    print(f\"Warning: Only {len(unique_records)} unique images available, less than requested {sample_size}\")\n",
    "    sampled_data = unique_records\n",
    "else:\n",
    "    # Use random.sample for sampling without replacement\n",
    "    random.seed(42)  # For reproducibility\n",
    "    sampled_data = random.sample(unique_records, sample_size)\n",
    "\n",
    "print(f\"Selected {len(sampled_data)} records for subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding UIDs and saving subset...\n",
      "Saved 15000 records to dvqa_int_only_15K_v1_subset.jsonl\n",
      "Sample record with UID: {'image': 'MMPR-v1.2-prompts/correctness_images/dvqa_en_20240402_extracted_int_only/images/bar_train_00023964.png', 'question': 'What is the value of the smallest individual bar in the whole chart? Answer the question using a single word or phrase.', 'answer': '2', 'uid': '70341b17-3467-4a92-b4bf-872853fd34c1'}\n"
     ]
    }
   ],
   "source": [
    "# Add UUID to each record and save subset\n",
    "subset_output_file = \"dvqa_int_only_15K_v1_subset.jsonl\"\n",
    "\n",
    "print(\"Adding UIDs and saving subset...\")\n",
    "with open(subset_output_file, 'w') as f:\n",
    "    for record in sampled_data:\n",
    "        # Add UID to the record\n",
    "        record_with_uid = record.copy()\n",
    "        record_with_uid[\"uid\"] = str(uuid.uuid4())\n",
    "        \n",
    "        # Write to file\n",
    "        f.write(json.dumps(record_with_uid) + \"\\n\")\n",
    "\n",
    "print(f\"Saved {len(sampled_data)} records to {subset_output_file}\")\n",
    "print(\"Sample record with UID:\", json.loads(open(subset_output_file).readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy images to subset_images directory\n",
    "subset_images_dir = \"subset_images\"\n",
    "os.makedirs(subset_images_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Copying images to {subset_images_dir} directory...\")\n",
    "\n",
    "# Read the subset file to get the image paths\n",
    "copied_count = 0\n",
    "failed_count = 0\n",
    "\n",
    "with open(subset_output_file, 'r') as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line.strip())\n",
    "        image_path = record[\"image\"]\n",
    "        \n",
    "        # Find the image file (assuming it's in the parent directory structure)\n",
    "        # The image path in the JSONL is relative, we need to find the actual file\n",
    "        source_image_path = f\"/data/users/brandon/ob1-projects/InternVL/{image_path}\"\n",
    "        \n",
    "        # Extract filename from path\n",
    "        image_filename = os.path.basename(image_path)\n",
    "        dest_image_path = os.path.join(subset_images_dir, image_filename)\n",
    "        \n",
    "        try:\n",
    "            if os.path.exists(source_image_path):\n",
    "                shutil.copy2(source_image_path, dest_image_path)\n",
    "                copied_count += 1\n",
    "            else:\n",
    "                print(f\"Warning: Source image not found: {source_image_path}\")\n",
    "                failed_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {source_image_path}: {e}\")\n",
    "            failed_count += 1\n",
    "\n",
    "print(f\"Successfully copied {copied_count} images\")\n",
    "print(f\"Failed to copy {failed_count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final JSONL with absolute image paths\n",
    "final_output_file = \"dvqa_run1_int_only.jsonl\"\n",
    "base_dir = \"/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/DVQA\"\n",
    "absolute_subset_images_dir = os.path.join(base_dir, \"subset_images\")\n",
    "\n",
    "print(f\"Creating final JSONL with absolute image paths: {final_output_file}\")\n",
    "\n",
    "with open(subset_output_file, 'r') as input_f, open(final_output_file, 'w') as output_f:\n",
    "    for line in input_f:\n",
    "        record = json.loads(line.strip())\n",
    "        \n",
    "        # Extract original filename\n",
    "        image_filename = os.path.basename(record[\"image\"])\n",
    "        \n",
    "        # Create absolute path to the copied image\n",
    "        absolute_image_path = os.path.join(absolute_subset_images_dir, image_filename)\n",
    "        \n",
    "        # Add the image_path field\n",
    "        record[\"image_path\"] = absolute_image_path\n",
    "        \n",
    "        # Write the updated record\n",
    "        output_f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "print(f\"Created final output file: {final_output_file}\")\n",
    "\n",
    "# Show sample of final output\n",
    "with open(final_output_file, 'r') as f:\n",
    "    sample_record = json.loads(f.readline())\n",
    "    print(\"Sample final record:\")\n",
    "    print(json.dumps(sample_record, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmr_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
