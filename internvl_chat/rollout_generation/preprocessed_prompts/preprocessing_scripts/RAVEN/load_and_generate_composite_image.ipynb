{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_composite_matrix_image(panels: List[Image.Image]) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Create a composite image showing the 8 panels arranged in a 3x3 grid layout\n",
    "    with borders around each panel, matching the reference style.\n",
    "    \n",
    "    Args:\n",
    "        panels: List of 8 PIL images representing the matrix panels\n",
    "        \n",
    "    Returns:\n",
    "        PIL Image showing the 3x3 matrix with missing bottom-right panel\n",
    "    \"\"\"\n",
    "    # Assume all panels are the same size\n",
    "    panel_width, panel_height = panels[0].size\n",
    "    \n",
    "    # Add border width and spacing\n",
    "    border_width = 2\n",
    "    spacing = 4\n",
    "    \n",
    "    # Calculate dimensions with borders and spacing\n",
    "    cell_width = panel_width + 2 * border_width\n",
    "    cell_height = panel_height + 2 * border_width\n",
    "    \n",
    "    # Add margin for the \"Problem Matrix\" text on the left side\n",
    "    left_margin = 60  # Margin for the vertical text - increased from 40 to 60\n",
    "    \n",
    "    composite_width = cell_width * 3 + spacing * 2 + left_margin\n",
    "    composite_height = cell_height * 3 + spacing * 2\n",
    "    \n",
    "    # Create composite image with white background\n",
    "    composite = Image.new('RGB', (composite_width, composite_height), 'white')\n",
    "    \n",
    "    draw = ImageDraw.Draw(composite)\n",
    "    \n",
    "    # Arrange panels in 3x3 grid (missing bottom-right)\n",
    "    positions = [\n",
    "        (0, 0),      # Panel 1: top-left\n",
    "        (1, 0),      # Panel 2: top-center  \n",
    "        (2, 0),      # Panel 3: top-right\n",
    "        (0, 1),      # Panel 4: middle-left\n",
    "        (1, 1),      # Panel 5: middle-center\n",
    "        (2, 1),      # Panel 6: middle-right\n",
    "        (0, 2),      # Panel 7: bottom-left\n",
    "        (1, 2),      # Panel 8: bottom-center\n",
    "        # (2, 2) is missing - bottom-right\n",
    "    ]\n",
    "    \n",
    "    for i, (col, row) in enumerate(positions):\n",
    "        # Calculate position with spacing, accounting for left margin\n",
    "        x = left_margin + col * (cell_width + spacing)\n",
    "        y = row * (cell_height + spacing)\n",
    "        \n",
    "        # Draw border rectangle\n",
    "        draw.rectangle([x, y, x + cell_width, y + cell_height], \n",
    "                      outline='black', fill='white', width=border_width)\n",
    "        \n",
    "        # Paste the panel inside the border\n",
    "        panel_x = x + border_width\n",
    "        panel_y = y + border_width\n",
    "        composite.paste(panels[i], (panel_x, panel_y))\n",
    "    \n",
    "    # Add question mark for missing panel\n",
    "    missing_col, missing_row = 2, 2\n",
    "    missing_x = left_margin + missing_col * (cell_width + spacing)\n",
    "    missing_y = missing_row * (cell_height + spacing)\n",
    "    \n",
    "    # Draw border for missing panel\n",
    "    draw.rectangle([missing_x, missing_y, missing_x + cell_width, missing_y + cell_height], \n",
    "                  outline='black', fill='white', width=border_width)\n",
    "    \n",
    "    # Add question mark in the center\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", \n",
    "                                min(panel_width, panel_height) // 3)\n",
    "    except:\n",
    "        try:\n",
    "            font = ImageFont.load_default()\n",
    "        except:\n",
    "            font = None\n",
    "    \n",
    "    question_text = \"?\"\n",
    "    if font:\n",
    "        bbox = draw.textbbox((0, 0), question_text, font=font)\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        text_height = bbox[3] - bbox[1]\n",
    "    else:\n",
    "        text_width, text_height = 20, 20\n",
    "    \n",
    "    text_x = missing_x + (cell_width - text_width) // 2\n",
    "    text_y = missing_y + (cell_height - text_height) // 2\n",
    "    \n",
    "    draw.text((text_x, text_y), question_text, fill='black', font=font)\n",
    "    \n",
    "    # Add \"Problem Matrix\" text on the left side\n",
    "    try:\n",
    "        label_font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 18)\n",
    "    except:\n",
    "        try:\n",
    "            label_font = ImageFont.load_default()\n",
    "        except:\n",
    "            label_font = None\n",
    "    \n",
    "    if label_font:\n",
    "        problem_matrix_text = \"Problem Matrix\"\n",
    "        text_width, text_height = draw.textbbox((0, 0), problem_matrix_text, font=label_font)[2:4]\n",
    "        \n",
    "        # Calculate the position for the vertical text\n",
    "        # Center it vertically in the matrix area\n",
    "        matrix_height = 3 * cell_height + 2 * spacing\n",
    "        text_x = 25  # Fixed distance from the left edge - increased from 15 to 25\n",
    "        text_y = (composite_height - text_width) // 2  # Center vertically\n",
    "        \n",
    "        # Draw the rotated text\n",
    "        # We need to create a temporary image, draw text, then rotate and paste\n",
    "        text_img = Image.new('RGBA', (text_width, text_height), (255, 255, 255, 0))\n",
    "        text_draw = ImageDraw.Draw(text_img)\n",
    "        text_draw.text((0, 0), problem_matrix_text, fill='black', font=label_font)\n",
    "        \n",
    "        # Rotate the text image 90 degrees counter-clockwise\n",
    "        rotated_text = text_img.rotate(90, expand=True)\n",
    "        \n",
    "        # Paste the rotated text onto the composite image\n",
    "        composite.paste(rotated_text, (text_x, text_y), rotated_text)\n",
    "    \n",
    "    return composite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_choices_grid(choices: List[Image.Image]) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Create a grid showing the 8 answer choices with index labels below each choice,\n",
    "    matching the reference style with 2 rows of 4 choices each.\n",
    "    \n",
    "    Args:\n",
    "        choices: List of 8 PIL images representing answer choices\n",
    "        \n",
    "    Returns:\n",
    "        PIL Image showing choices arranged in 2x4 grid with labels below\n",
    "    \"\"\"\n",
    "    choice_width, choice_height = choices[0].size\n",
    "    \n",
    "    # Grid configuration: 2 rows, 4 columns\n",
    "    grid_cols, grid_rows = 4, 2\n",
    "    \n",
    "    # Add border width and spacing\n",
    "    border_width = 2\n",
    "    spacing = 4\n",
    "    label_height = 30  # Space for number labels below choices\n",
    "    \n",
    "    # Calculate cell dimensions\n",
    "    cell_width = choice_width + 2 * border_width\n",
    "    cell_height = choice_height + 2 * border_width + label_height\n",
    "    \n",
    "    # Calculate total dimensions\n",
    "    composite_width = cell_width * grid_cols + spacing * (grid_cols - 1)\n",
    "    composite_height = cell_height * grid_rows + spacing * (grid_rows - 1)\n",
    "    \n",
    "    composite = Image.new('RGB', (composite_width, composite_height), 'white')\n",
    "    \n",
    "    draw = ImageDraw.Draw(composite)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 18)\n",
    "    except:\n",
    "        try:\n",
    "            font = ImageFont.load_default()\n",
    "        except:\n",
    "            font = None\n",
    "    \n",
    "    for i, choice in enumerate(choices):\n",
    "        col = i % grid_cols\n",
    "        row = i // grid_cols\n",
    "        \n",
    "        # Calculate position with spacing\n",
    "        x = col * (cell_width + spacing)\n",
    "        y = row * (cell_height + spacing)\n",
    "        \n",
    "        # Draw border rectangle around choice\n",
    "        choice_border_height = choice_height + 2 * border_width\n",
    "        draw.rectangle([x, y, x + cell_width, y + choice_border_height], \n",
    "                      outline='black', fill='white', width=border_width)\n",
    "        \n",
    "        # Paste the choice image inside the border\n",
    "        choice_x = x + border_width\n",
    "        choice_y = y + border_width\n",
    "        composite.paste(choice, (choice_x, choice_y))\n",
    "        \n",
    "        # Add index label below the choice\n",
    "        label = str(i + 1)  # 1-indexed for display\n",
    "        if font:\n",
    "            bbox = draw.textbbox((0, 0), label, font=font)\n",
    "            text_width = bbox[2] - bbox[0]\n",
    "            text_height = bbox[3] - bbox[1]\n",
    "        else:\n",
    "            text_width, text_height = 10, 12\n",
    "        \n",
    "        # Center the label below the choice\n",
    "        label_x = x + (cell_width - text_width) // 2\n",
    "        label_y = y + choice_border_height + (label_height - text_height) // 2\n",
    "        \n",
    "        draw.text((label_x, label_y), label, fill='black', font=font)\n",
    "    \n",
    "    return composite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_image(matrix_composite: Image.Image, choices_composite: Image.Image) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Combine matrix composite and choices composite into a single image matching\n",
    "    the reference layout with section labels and proper spacing.\n",
    "    \n",
    "    Args:\n",
    "        matrix_composite: PIL Image showing the 3x3 matrix\n",
    "        choices_composite: PIL Image showing the 8 choices\n",
    "        \n",
    "    Returns:\n",
    "        PIL Image with labeled sections: Problem Matrix and Answer Set\n",
    "    \"\"\"\n",
    "    # Calculate dimensions\n",
    "    matrix_width, matrix_height = matrix_composite.size\n",
    "    choices_width, choices_height = choices_composite.size\n",
    "    \n",
    "    # Layout parameters\n",
    "    margin = 30  # Margin around the entire image\n",
    "    section_spacing = 40  # Space between Problem Matrix and Answer Set\n",
    "    label_height = 40  # Height for section labels (increased)\n",
    "    label_margin = 15  # Space between label and content (increased)\n",
    "    \n",
    "    # Add margin for the left side labels\n",
    "    left_margin = 120  # Increased from 90 to 120 for more space for vertical text\n",
    "    \n",
    "    # Calculate total dimensions\n",
    "    combined_width = max(matrix_width, choices_width) + 2 * margin + left_margin\n",
    "    combined_height = (margin + label_height + label_margin + matrix_height + \n",
    "                      section_spacing + label_height + label_margin + \n",
    "                      choices_height + margin)\n",
    "    \n",
    "    # Create combined image with white background\n",
    "    combined = Image.new('RGB', (combined_width, combined_height), 'white')\n",
    "    draw = ImageDraw.Draw(combined)\n",
    "    \n",
    "    # Set up fonts - using bold font for both\n",
    "    try:\n",
    "        title_font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 20)\n",
    "        label_font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 18)\n",
    "    except:\n",
    "        try:\n",
    "            title_font = ImageFont.load_default()\n",
    "            label_font = ImageFont.load_default()\n",
    "        except:\n",
    "            title_font = None\n",
    "            label_font = None\n",
    "    \n",
    "    # Current y position\n",
    "    current_y = margin\n",
    "    \n",
    "    # Add \"(a)\" label at top left\n",
    "    # if title_font:\n",
    "        # draw.text((margin, current_y), \"(a)\", fill='black', font=title_font)\n",
    "    current_y += label_height + label_margin\n",
    "    \n",
    "    # We don't need to add \"Problem Matrix\" label here since it's now part of the matrix_composite\n",
    "    \n",
    "    # Center and paste the matrix\n",
    "    matrix_x = margin + (combined_width - matrix_width - 2*margin) // 2\n",
    "    combined.paste(matrix_composite, (matrix_x, current_y))\n",
    "    current_y += matrix_height + section_spacing\n",
    "    \n",
    "    # Add \"Answer Set\" label - positioned on the left side vertically\n",
    "    if label_font:\n",
    "        answer_set_label = \"Answer Set\"\n",
    "        # Create a temporary image for the rotated text\n",
    "        bbox = draw.textbbox((0, 0), answer_set_label, font=label_font)\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        text_height = bbox[3] - bbox[1]\n",
    "        \n",
    "        # Create temporary image for text with transparent background\n",
    "        text_img = Image.new('RGBA', (text_width + 10, text_height + 10), (255, 255, 255, 0))  # Added padding\n",
    "        text_draw = ImageDraw.Draw(text_img)\n",
    "        text_draw.text((5, 5), answer_set_label, fill='black', font=label_font)  # Add some padding inside the text image\n",
    "        \n",
    "        # Rotate the text image 90 degrees counter-clockwise\n",
    "        rotated_text = text_img.rotate(90, expand=True)\n",
    "        \n",
    "        # Position the rotated text on the left side, centered vertically with choices grid\n",
    "        # Ensure text is more centered and not cut off\n",
    "        label_x = 45  # Increased from 35 to 45 for better spacing\n",
    "        \n",
    "        # Calculate better vertical centering based on the actual choices area\n",
    "        # Make sure the text is fully visible within the choices section\n",
    "        choices_center_y = current_y + choices_height / 2\n",
    "        rotated_text_height = rotated_text.size[1]\n",
    "        label_y = choices_center_y - rotated_text_height / 2\n",
    "        \n",
    "        # Ensure the text doesn't go outside the image boundaries\n",
    "        if label_y < current_y:\n",
    "            label_y = current_y\n",
    "        if label_y + rotated_text_height > current_y + choices_height:\n",
    "            label_y = current_y + choices_height - rotated_text_height\n",
    "            \n",
    "        combined.paste(rotated_text, (label_x, int(label_y)), rotated_text)\n",
    "    \n",
    "    # Center and paste the choices\n",
    "    choices_x = margin + (combined_width - choices_width - 2*margin) // 2\n",
    "    combined.paste(choices_composite, (choices_x, current_y))\n",
    "    \n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded center_single dataset with the following splits: dict_keys(['train', 'validation', 'test'])\n",
      "Training examples: 6000\n",
      "Validation examples: 2000\n",
      "\n",
      "Loaded distribute_four dataset with the following splits: dict_keys(['train', 'validation', 'test'])\n",
      "Training examples: 6000\n",
      "Validation examples: 2000\n",
      "\n",
      "Loaded distribute_nine dataset with the following splits: dict_keys(['train', 'validation', 'test'])\n",
      "Training examples: 6000\n",
      "Validation examples: 2000\n"
     ]
    }
   ],
   "source": [
    "# Load the RAVEN dataset - for all required subsets\n",
    "subsets = [\"center_single\", \"distribute_four\", \"distribute_nine\"]\n",
    "\n",
    "# have a different shape\n",
    "# subsets = [\"left_center_single_right_center_single\", \"up_center_single_down_center_single\", \"in_center_single_out_center_single\", \"in_distribute_four_out_center_single\"]\n",
    "datasets = {}\n",
    "\n",
    "for subset in subsets:\n",
    "    datasets[subset] = load_dataset(\"HuggingFaceM4/RAVEN\", subset)\n",
    "    print(f\"\\nLoaded {subset} dataset with the following splits: {datasets[subset].keys()}\")\n",
    "    print(f\"Training examples: {len(datasets[subset]['train'])}\")\n",
    "    print(f\"Validation examples: {len(datasets[subset]['validation'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample from center_single ===\n",
      "Sample keys: dict_keys(['panels', 'choices', 'structure', 'meta_matrix', 'meta_target', 'meta_structure', 'target', 'id', 'metadata'])\n",
      "Panels length: 8\n",
      "Choices length: 8\n",
      "Target: 4\n",
      "\n",
      "=== Sample from distribute_four ===\n",
      "Sample keys: dict_keys(['panels', 'choices', 'structure', 'meta_matrix', 'meta_target', 'meta_structure', 'target', 'id', 'metadata'])\n",
      "Panels length: 8\n",
      "Choices length: 8\n",
      "Target: 7\n",
      "\n",
      "=== Sample from distribute_nine ===\n",
      "Sample keys: dict_keys(['panels', 'choices', 'structure', 'meta_matrix', 'meta_target', 'meta_structure', 'target', 'id', 'metadata'])\n",
      "Panels length: 8\n",
      "Choices length: 8\n",
      "Target: 6\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of a sample from each dataset\n",
    "for subset in subsets:\n",
    "    sample = datasets[subset]['train'][0]\n",
    "    print(f\"\\n=== Sample from {subset} ===\")\n",
    "    print(\"Sample keys:\", sample.keys())\n",
    "    \n",
    "    # Print shape of panels and choices\n",
    "    print(\"Panels length:\", len(sample['panels']))\n",
    "    print(\"Choices length:\", len(sample['choices']))\n",
    "    print(\"Target:\", sample['target'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory structure for saving images\n",
    "import os\n",
    "base_dir = \"processed_raven_images\"\n",
    "for subset in subsets:\n",
    "    subset_dir = os.path.join(base_dir, subset)\n",
    "    os.makedirs(subset_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(subset_dir, \"train\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(subset_dir, \"validation\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process each dataset to create composite images - testing on 3 samples first\n",
    "# for subset in subsets:\n",
    "#     print(f\"\\nProcessing {subset} dataset (testing on 3 samples)...\")\n",
    "    \n",
    "#     # Process 3 samples from train set\n",
    "#     train_subset = datasets[subset]['train'].select(range(3))\n",
    "#     train_subset = train_subset.map(\n",
    "#         lambda x: {\n",
    "#             'problem_matrix_image': create_composite_matrix_image(x['panels']),\n",
    "#             'answer_set_image': create_choices_grid(x['choices'])\n",
    "#         },\n",
    "#         # remove_columns=['panels', 'choices']  # Remove original columns since we have composites\n",
    "#     )\n",
    "    \n",
    "#     # Process 3 samples from validation set\n",
    "#     val_subset = datasets[subset]['validation'].select(range(3))\n",
    "#     val_subset = val_subset.map(\n",
    "#         lambda x: {\n",
    "#             'problem_matrix_image': create_composite_matrix_image(x['panels']),\n",
    "#             'answer_set_image': create_choices_grid(x['choices'])\n",
    "#         },\n",
    "#         # remove_columns=['panels', 'choices']  # Remove original columns since we have composites\n",
    "#     )\n",
    "    \n",
    "#     # Update the dataset in the dictionary (with test samples only)\n",
    "#     datasets[subset] = {\n",
    "#         'train': train_subset,\n",
    "#         'validation': val_subset\n",
    "#     }\n",
    "    \n",
    "#     print(f\"Completed processing test samples for {subset} dataset\")\n",
    "#     print(f\"Train test set size: {len(train_subset)}\")\n",
    "#     print(f\"Validation test set size: {len(val_subset)}\")\n",
    "\n",
    "# # Verify the new structure\n",
    "# for subset in subsets:\n",
    "#     sample = datasets[subset]['train'][0]\n",
    "#     print(f\"\\n=== Sample from {subset} after processing ===\")\n",
    "#     print(\"Sample keys:\", sample.keys())\n",
    "#     print(\"Problem matrix image type:\", type(sample['problem_matrix_image']))\n",
    "#     print(\"Answer set image type:\", type(sample['answer_set_image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process and save combined images\n",
    "# base_dir = \"/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images\"\n",
    "\n",
    "# for subset in subsets:\n",
    "#     print(f\"\\nProcessing and saving combined images for {subset}...\")\n",
    "    \n",
    "#     # Process train set\n",
    "#     for idx, sample in enumerate(datasets[subset]['train']):\n",
    "#         combined_image = create_combined_image(\n",
    "#             sample['problem_matrix_image'],\n",
    "#             sample['answer_set_image']\n",
    "#         )\n",
    "#         save_path = os.path.join(base_dir, subset, \"train\", f\"{sample['id']}.png\")\n",
    "#         combined_image.save(save_path)\n",
    "#         if idx < 3:  # Print progress for first 3 samples\n",
    "#             print(f\"Saved train image {idx+1}/3: {save_path}\")\n",
    "    \n",
    "#     # Process validation set\n",
    "#     for idx, sample in enumerate(datasets[subset]['validation']):\n",
    "#         combined_image = create_combined_image(\n",
    "#             sample['problem_matrix_image'],\n",
    "#             sample['answer_set_image']\n",
    "#         )\n",
    "#         save_path = os.path.join(base_dir, subset, \"validation\", f\"{sample['id']}.png\")\n",
    "#         combined_image.save(save_path)\n",
    "#         if idx < 3:  # Print progress for first 3 samples\n",
    "#             print(f\"Saved validation image {idx+1}/3: {save_path}\")\n",
    "\n",
    "# print(\"\\nCompleted saving all combined images!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process and save combined images for full dataset with quality checks\n",
    "# base_dir = \"/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images\"\n",
    "\n",
    "# def verify_image_count(directory, expected_count):\n",
    "#     \"\"\"Verify the number of images in a directory matches expected count\"\"\"\n",
    "#     actual_count = len([f for f in os.listdir(directory) if f.endswith('.png')])\n",
    "#     if actual_count != expected_count:\n",
    "#         raise ValueError(f\"Image count mismatch in {directory}. Expected {expected_count}, got {actual_count}\")\n",
    "#     return actual_count\n",
    "\n",
    "# def verify_image_quality(image_path):\n",
    "#     \"\"\"Verify image can be opened and has valid dimensions\"\"\"\n",
    "#     try:\n",
    "#         img = Image.open(image_path)\n",
    "#         width, height = img.size\n",
    "#         if width < 100 or height < 100:  # Basic size check\n",
    "#             raise ValueError(f\"Image {image_path} has invalid dimensions: {width}x{height}\")\n",
    "#         return True\n",
    "#     except Exception as e:\n",
    "#         raise ValueError(f\"Failed to verify image {image_path}: {str(e)}\")\n",
    "\n",
    "# for subset in subsets:\n",
    "#     print(f\"\\nProcessing {subset} dataset...\")\n",
    "    \n",
    "#     # Get expected counts\n",
    "#     expected_train = len(datasets[subset]['train'])\n",
    "#     expected_val = len(datasets[subset]['validation'])\n",
    "#     print(f\"Expected counts - Train: {expected_train}, Validation: {expected_val}\")\n",
    "    \n",
    "#     # Process full train set\n",
    "#     print(f\"Processing train set ({expected_train} samples)...\")\n",
    "#     train_dataset = datasets[subset]['train'].map(\n",
    "#         lambda x: {\n",
    "#             'problem_matrix_image': create_composite_matrix_image(x['panels']),\n",
    "#             'answer_set_image': create_choices_grid(x['choices'])\n",
    "#         },\n",
    "#         remove_columns=['panels', 'choices']\n",
    "#     )\n",
    "    \n",
    "#     # Process full validation set\n",
    "#     print(f\"Processing validation set ({expected_val} samples)...\")\n",
    "#     val_dataset = datasets[subset]['validation'].map(\n",
    "#         lambda x: {\n",
    "#             'problem_matrix_image': create_composite_matrix_image(x['panels']),\n",
    "#             'answer_set_image': create_choices_grid(x['choices'])\n",
    "#         },\n",
    "#         remove_columns=['panels', 'choices']\n",
    "#     )\n",
    "    \n",
    "#     # Create directories if they don't exist\n",
    "#     train_dir = os.path.join(base_dir, subset, \"train\")\n",
    "#     val_dir = os.path.join(base_dir, subset, \"validation\")\n",
    "#     os.makedirs(train_dir, exist_ok=True)\n",
    "#     os.makedirs(val_dir, exist_ok=True)\n",
    "    \n",
    "#     # Save train images\n",
    "#     print(\"Saving train images...\")\n",
    "#     train_ids = set()  # Track unique IDs\n",
    "#     for idx, sample in enumerate(train_dataset):\n",
    "#         if sample['id'] in train_ids:\n",
    "#             raise ValueError(f\"Duplicate ID found in train set: {sample['id']}\")\n",
    "#         train_ids.add(sample['id'])\n",
    "        \n",
    "#         combined_image = create_combined_image(\n",
    "#             sample['problem_matrix_image'],\n",
    "#             sample['answer_set_image']\n",
    "#         )\n",
    "#         save_path = os.path.join(train_dir, f\"{sample['id']}.png\")\n",
    "#         combined_image.save(save_path)\n",
    "        \n",
    "#         # Verify image quality\n",
    "#         verify_image_quality(save_path)\n",
    "        \n",
    "#         if idx % 100 == 0:\n",
    "#             print(f\"Saved {idx}/{expected_train} train images\")\n",
    "    \n",
    "#     # Save validation images\n",
    "#     print(\"Saving validation images...\")\n",
    "#     val_ids = set()  # Track unique IDs\n",
    "#     for idx, sample in enumerate(val_dataset):\n",
    "#         if sample['id'] in val_ids:\n",
    "#             raise ValueError(f\"Duplicate ID found in validation set: {sample['id']}\")\n",
    "#         val_ids.add(sample['id'])\n",
    "        \n",
    "#         combined_image = create_combined_image(\n",
    "#             sample['problem_matrix_image'],\n",
    "#             sample['answer_set_image']\n",
    "#         )\n",
    "#         save_path = os.path.join(val_dir, f\"{sample['id']}.png\")\n",
    "#         combined_image.save(save_path)\n",
    "        \n",
    "#         # Verify image quality\n",
    "#         verify_image_quality(save_path)\n",
    "        \n",
    "#         if idx % 100 == 0:\n",
    "#             print(f\"Saved {idx}/{expected_val} validation images\")\n",
    "    \n",
    "#     # Verify final counts\n",
    "#     print(\"\\nVerifying final counts...\")\n",
    "#     actual_train = verify_image_count(train_dir, expected_train)\n",
    "#     actual_val = verify_image_count(val_dir, expected_val)\n",
    "#     print(f\"Verified counts for {subset}:\")\n",
    "#     print(f\"Train: {actual_train}/{expected_train}\")\n",
    "#     print(f\"Validation: {actual_val}/{expected_val}\")\n",
    "    \n",
    "#     # Verify no overlap between train and validation IDs\n",
    "#     if train_ids.intersection(val_ids):\n",
    "#         raise ValueError(f\"Found overlapping IDs between train and validation sets in {subset}\")\n",
    "    \n",
    "#     print(f\"Completed processing {subset} dataset with all quality checks passed\")\n",
    "\n",
    "# print(\"\\nCompleted processing all datasets with quality checks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing center_single dataset...\n",
      "Expected counts - Train: 6000, Validation: 2000\n",
      "Processing train set (6000 samples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c252dd548a4430876f44ce9aa9d0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing train set (num_proc=192):   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing validation set (2000 samples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4ecc4e042541f38aa89bcd2d085f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing validation set (num_proc=192):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying final counts...\n",
      "Verified counts for center_single:\n",
      "Train: 6000/6000\n",
      "Validation: 2000/2000\n",
      "Completed processing center_single dataset with all quality checks passed\n",
      "\n",
      "Processing distribute_four dataset...\n",
      "Expected counts - Train: 6000, Validation: 2000\n",
      "Processing train set (6000 samples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70788b121bd0428d8b58ed1fcb544df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing train set (num_proc=192):   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing validation set (2000 samples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062449b3ad92417fab9f61b5125bbfde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing validation set (num_proc=192):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying final counts...\n",
      "Verified counts for distribute_four:\n",
      "Train: 6000/6000\n",
      "Validation: 2000/2000\n",
      "Completed processing distribute_four dataset with all quality checks passed\n",
      "\n",
      "Processing distribute_nine dataset...\n",
      "Expected counts - Train: 6000, Validation: 2000\n",
      "Processing train set (6000 samples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51663df9a054bdb9e49bfa3f3d75d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing train set (num_proc=192):   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing validation set (2000 samples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b68f47c3ac94ec9afb539cc59705131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing validation set (num_proc=192):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying final counts...\n",
      "Verified counts for distribute_nine:\n",
      "Train: 6000/6000\n",
      "Validation: 2000/2000\n",
      "Completed processing distribute_nine dataset with all quality checks passed\n",
      "\n",
      "Completed processing all datasets with quality checks!\n"
     ]
    }
   ],
   "source": [
    "# Process and save combined images for full dataset with quality checks and parallelization\n",
    "base_dir = \"/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images\"\n",
    "\n",
    "def verify_image_count(directory, expected_count):\n",
    "    \"\"\"Verify the number of images in a directory matches expected count\"\"\"\n",
    "    actual_count = len([f for f in os.listdir(directory) if f.endswith('.png')])\n",
    "    if actual_count != expected_count:\n",
    "        raise ValueError(f\"Image count mismatch in {directory}. Expected {expected_count}, got {actual_count}\")\n",
    "    return actual_count\n",
    "\n",
    "def verify_image_quality(image_path):\n",
    "    \"\"\"Verify image can be opened and has valid dimensions\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        width, height = img.size\n",
    "        if width < 100 or height < 100:  # Basic size check\n",
    "            raise ValueError(f\"Image {image_path} has invalid dimensions: {width}x{height}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to verify image {image_path}: {str(e)}\")\n",
    "\n",
    "def process_and_save_batch(batch, subset, split, base_dir):\n",
    "    \"\"\"Process a batch of samples and save their images\"\"\"\n",
    "    # Create the correct directory based on split (train/validation)\n",
    "    save_dir = os.path.join(base_dir, subset, split)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    results = []\n",
    "    for sample in batch:\n",
    "        # Create composite images\n",
    "        problem_matrix = create_composite_matrix_image(sample['panels'])\n",
    "        answer_set = create_choices_grid(sample['choices'])\n",
    "        \n",
    "        # Create and save combined image\n",
    "        combined_image = create_combined_image(problem_matrix, answer_set)\n",
    "        save_path = os.path.join(save_dir, f\"{sample['id']}.png\")\n",
    "        combined_image.save(save_path)\n",
    "        \n",
    "        # Verify image quality\n",
    "        verify_image_quality(save_path)\n",
    "        \n",
    "        results.append({\n",
    "            'id': sample['id'],\n",
    "            'path': save_path\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "for subset in subsets:\n",
    "    print(f\"\\nProcessing {subset} dataset...\")\n",
    "    \n",
    "    # Get expected counts\n",
    "    expected_train = len(datasets[subset]['train'])\n",
    "    expected_val = len(datasets[subset]['validation'])\n",
    "    print(f\"Expected counts - Train: {expected_train}, Validation: {expected_val}\")\n",
    "    \n",
    "    # Process train set with parallelization\n",
    "    print(f\"Processing train set ({expected_train} samples)...\")\n",
    "    train_results = datasets[subset]['train'].map(\n",
    "        lambda x: process_and_save_batch([x], subset, \"train\", base_dir)[0],\n",
    "        num_proc=os.cpu_count(),  # Use all available CPU cores\n",
    "        batch_size=32,  # Process in batches for better efficiency\n",
    "        desc=\"Processing train set\",\n",
    "        remove_columns=['panels', 'choices']\n",
    "    )\n",
    "    \n",
    "    # Process validation set with parallelization\n",
    "    print(f\"Processing validation set ({expected_val} samples)...\")\n",
    "    val_results = datasets[subset]['validation'].map(\n",
    "        lambda x: process_and_save_batch([x], subset, \"validation\", base_dir)[0],\n",
    "        num_proc=os.cpu_count(),  # Use all available CPU cores\n",
    "        batch_size=32,  # Process in batches for better efficiency\n",
    "        desc=\"Processing validation set\",\n",
    "        remove_columns=['panels', 'choices']\n",
    "    )\n",
    "    \n",
    "    # Collect all IDs for verification\n",
    "    train_ids = set(result['id'] for result in train_results)\n",
    "    val_ids = set(result['id'] for result in val_results)\n",
    "    \n",
    "    # Verify final counts\n",
    "    print(\"\\nVerifying final counts...\")\n",
    "    actual_train = verify_image_count(os.path.join(base_dir, subset, \"train\"), expected_train)\n",
    "    actual_val = verify_image_count(os.path.join(base_dir, subset, \"validation\"), expected_val)\n",
    "    print(f\"Verified counts for {subset}:\")\n",
    "    print(f\"Train: {actual_train}/{expected_train}\")\n",
    "    print(f\"Validation: {actual_val}/{expected_val}\")\n",
    "    \n",
    "    # Verify no overlap between train and validation IDs\n",
    "    if train_ids.intersection(val_ids):\n",
    "        raise ValueError(f\"Found overlapping IDs between train and validation sets in {subset}\")\n",
    "    \n",
    "    print(f\"Completed processing {subset} dataset with all quality checks passed\")\n",
    "\n",
    "print(\"\\nCompleted processing all datasets with quality checks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmr_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
