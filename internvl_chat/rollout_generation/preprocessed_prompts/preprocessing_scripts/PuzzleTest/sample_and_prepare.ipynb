{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 JSON files:\n",
      "  - circle_size_number.json\n",
      "  - color_grid.json\n",
      "  - color_hexagon.json\n",
      "  - color_number_hexagon.json\n",
      "  - color_overlap_squares.json\n",
      "  - color_size_circle.json\n",
      "  - grid_number.json\n",
      "  - grid_number_color.json\n",
      "  - polygon_sides_color.json\n",
      "  - polygon_sides_number.json\n",
      "  - rectangle_height_color.json\n",
      "  - rectangle_height_number.json\n",
      "  - shape_morph.json\n",
      "  - shape_reflect.json\n",
      "  - shape_size_grid.json\n",
      "  - shape_size_hexagon.json\n",
      "  - size_cycle.json\n",
      "  - size_grid.json\n",
      "  - triangle.json\n",
      "  - venn.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Path to the AlgoPuzzleVQA data directory\n",
    "# data_dir = \"AlgoPuzzleVQA/data\"\n",
    "data_dir = \"PuzzleVQA/data\"\n",
    "\n",
    "# Find all JSON files in the data directory\n",
    "json_files = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith('.json'):\n",
    "        json_files.append(file)\n",
    "\n",
    "print(f\"Found {len(json_files)} JSON files:\")\n",
    "for file in json_files:\n",
    "    print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total files: 20\n",
      "Split point: 10\n",
      "\n",
      "Training files (10):\n",
      "  - venn.json\n",
      "  - color_size_circle.json\n",
      "  - shape_size_grid.json\n",
      "  - color_overlap_squares.json\n",
      "  - polygon_sides_number.json\n",
      "  - shape_reflect.json\n",
      "  - shape_size_hexagon.json\n",
      "  - triangle.json\n",
      "  - grid_number.json\n",
      "  - shape_morph.json\n",
      "\n",
      "Testing files (10):\n",
      "  - size_grid.json\n",
      "  - rectangle_height_color.json\n",
      "  - color_grid.json\n",
      "  - rectangle_height_number.json\n",
      "  - color_hexagon.json\n",
      "  - size_cycle.json\n",
      "  - grid_number_color.json\n",
      "  - polygon_sides_color.json\n",
      "  - circle_size_number.json\n",
      "  - color_number_hexagon.json\n"
     ]
    }
   ],
   "source": [
    "# Calculate split point (half of total files)\n",
    "total_files = len(json_files)\n",
    "split_point = total_files // 2\n",
    "\n",
    "# Randomly split into training and testing sets\n",
    "random.shuffle(json_files)\n",
    "train_files = json_files[:split_point]\n",
    "test_files = json_files[split_point:]\n",
    "\n",
    "print(f\"\\nTotal files: {total_files}\")\n",
    "print(f\"Split point: {split_point}\")\n",
    "print(f\"\\nTraining files ({len(train_files)}):\")\n",
    "for file in train_files:\n",
    "    print(f\"  - {file}\")\n",
    "\n",
    "print(f\"\\nTesting files ({len(test_files)}):\")\n",
    "for file in test_files:\n",
    "    print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json_files(file_list, output_file):\n",
    "    \"\"\"Flatten multiple JSON files into a single JSONL file\"\"\"\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for json_file in file_list:\n",
    "            file_path = os.path.join(data_dir, json_file)\n",
    "            print(f\"Processing {json_file}...\")\n",
    "            \n",
    "            with open(file_path, 'r') as infile:\n",
    "                for line in infile:\n",
    "                    line = line.strip()\n",
    "                    if line:  # Skip empty lines\n",
    "                        # Parse the JSON object and write it to the output file\n",
    "                        try:\n",
    "                            json_obj = json.loads(line)\n",
    "                            # Add source_file field to track origin\n",
    "                            json_obj[\"source_file\"] = json_file\n",
    "                            outfile.write(json.dumps(json_obj) + '\\n')\n",
    "                        except json.JSONDecodeError as e:\n",
    "                            print(f\"Warning: Could not parse JSON in {json_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating training JSONL file...\n",
      "Processing venn.json...\n",
      "Processing color_size_circle.json...\n",
      "Processing shape_size_grid.json...\n",
      "Processing color_overlap_squares.json...\n",
      "Processing polygon_sides_number.json...\n",
      "Processing shape_reflect.json...\n",
      "Processing shape_size_hexagon.json...\n",
      "Processing triangle.json...\n",
      "Processing grid_number.json...\n",
      "Processing shape_morph.json...\n"
     ]
    }
   ],
   "source": [
    "# Create training JSONL file\n",
    "print(\"\\nCreating training JSONL file...\")\n",
    "flatten_json_files(train_files, \"PuzzleVQA_train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating testing JSONL file...\n",
      "Processing size_grid.json...\n",
      "Processing rectangle_height_color.json...\n",
      "Processing color_grid.json...\n",
      "Processing rectangle_height_number.json...\n",
      "Processing color_hexagon.json...\n",
      "Processing size_cycle.json...\n",
      "Processing grid_number_color.json...\n",
      "Processing polygon_sides_color.json...\n",
      "Processing circle_size_number.json...\n",
      "Processing color_number_hexagon.json...\n"
     ]
    }
   ],
   "source": [
    "# Create testing JSONL file\n",
    "print(\"\\nCreating testing JSONL file...\")\n",
    "flatten_json_files(test_files, \"PuzzleVQA_test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training file: PuzzleVQA_train.jsonl (1000 records)\n",
      "Testing file: PuzzleVQA_test.jsonl (1000 records)\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Count lines in output files\n",
    "def count_lines(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return sum(1 for line in f)\n",
    "\n",
    "# print(f\"\\nTraining file: AlgoPuzzleVQA_train.jsonl ({count_lines('AlgoPuzzleVQA_train.jsonl')} records)\")\n",
    "# print(f\"Testing file: AlgoPuzzleVQA_test.jsonl ({count_lines('AlgoPuzzleVQA_test.jsonl')} records)\")\n",
    "print(f\"\\nTraining file: PuzzleVQA_train.jsonl ({count_lines('PuzzleVQA_train.jsonl')} records)\")\n",
    "print(f\"Testing file: PuzzleVQA_test.jsonl ({count_lines('PuzzleVQA_test.jsonl')} records)\")\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample record with UID: {'image': 'images/venn/venn_0000.png', 'question': 'What is the missing number of the part denoted with a question mark?', 'answer': 1, 'options': ['4', '8', '1', '9'], 'caption': \"There are 3 overlapping circles containing the numbers [7, 9, '?']. The overlapping part between the first and second circle contains the number 16. The overlapping part between the second and third circle contains the number 10.\", 'explanation': 'We observe that the circles with 7 and 9 overlap to form the part 16, where 7 + 9 = 16. Hence, the pattern is most likely that the numbers in the overlapping parts are the sum of the numbers in the corresponding circles.', 'deduction': 'Based on the pattern that the numbers in the overlapping parts are the sum of the numbers in the corresponding circles, the missing number of the circle where the overlapping part is 10 should be 1.', 'source_file': 'venn.json'}\n"
     ]
    }
   ],
   "source": [
    "subset_output_file = \"PuzzleVQA_train.jsonl\"\n",
    "print(\"Sample record with UID:\", json.loads(open(subset_output_file).readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_source_image_path:  /data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/PuzzleTest/PuzzleVQA/data/images/venn/venn_0000.png\n",
      "image_filename:  venn_0000.png\n"
     ]
    }
   ],
   "source": [
    "source_image_dir = \"/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/PuzzleTest/PuzzleVQA/data/images\"\n",
    "loaded_image_path = \"images/venn/venn_0000.png\"\n",
    "\n",
    "source_image_path = \"/\".join(loaded_image_path.split(\"/\")[1::])\n",
    "full_source_image_path = os.path.join(source_image_dir, source_image_path)\n",
    "\n",
    "print(\"full_source_image_path: \", full_source_image_path)\n",
    "# print(\"loaded_image_path: \", loaded_image_path)\n",
    "\n",
    "\n",
    "image_filename = os.path.basename(loaded_image_path)\n",
    "print(\"image_filename: \", image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating final JSONL with absolute image paths: AlgoPuzzleVQA_train_run1_1K_v1_subset.jsonl\n",
      "Created final output file: AlgoPuzzleVQA_train_run1_1K_v1_subset.jsonl\n",
      "Sample final record:\n",
      "{\n",
      "  \"image\": \"images/think_dot/think_dot_0000.jpg\",\n",
      "  \"question\": \"The toy shown in the figure has eight coloured disks on its front, and three holes on its top \\u2013 left, right, and center \\u2013 through which a ball bearing could be dropped. Each disk would display either a yellow or blue face. When a ball passes through a disc it tips the disk mechanism which flips the face color. The tipping of the disc mechanism determines whether the ball would be deflected to the left or to the right. The vertical walls between the discs would then determine the path of motion of the ball. A dropped ball always passes through exactly one disc in each of the top and the bottom row. Depending on the configuration of the top three discs it may or may not pass through the middle row. Finally, when the ball falls to the bottom it would exit either to a hole on the left or the right of the device. One ball in dropped through the left hole. Consider the toy configuration after the ball has been dropped and it has exited from the bottom. How many yellow faces can be seen in the top row now?\",\n",
      "  \"options\": [\n",
      "    \"7\",\n",
      "    \"8\",\n",
      "    \"4\",\n",
      "    \"1\"\n",
      "  ],\n",
      "  \"answer\": \"1\",\n",
      "  \"solution\": {\n",
      "    \"start_state\": [\n",
      "      [\n",
      "        \"blue\",\n",
      "        \"blue\",\n",
      "        \"blue\"\n",
      "      ],\n",
      "      [\n",
      "        \"blue\",\n",
      "        \"blue\"\n",
      "      ],\n",
      "      [\n",
      "        \"blue\",\n",
      "        \"blue\",\n",
      "        \"blue\"\n",
      "      ]\n",
      "    ],\n",
      "    \"moves\": [\n",
      "      \"left\"\n",
      "    ],\n",
      "    \"state_after_moves\": [\n",
      "      [\n",
      "        [\n",
      "          \"yellow\",\n",
      "          \"blue\",\n",
      "          \"blue\"\n",
      "        ],\n",
      "        [\n",
      "          \"yellow\",\n",
      "          \"blue\"\n",
      "        ],\n",
      "        [\n",
      "          \"yellow\",\n",
      "          \"blue\",\n",
      "          \"blue\"\n",
      "        ]\n",
      "      ]\n",
      "    ],\n",
      "    \"final_state\": [\n",
      "      [\n",
      "        \"yellow\",\n",
      "        \"blue\",\n",
      "        \"blue\"\n",
      "      ],\n",
      "      [\n",
      "        \"yellow\",\n",
      "        \"blue\"\n",
      "      ],\n",
      "      [\n",
      "        \"yellow\",\n",
      "        \"blue\",\n",
      "        \"blue\"\n",
      "      ]\n",
      "    ]\n",
      "  },\n",
      "  \"source_file\": \"think_dot.json\",\n",
      "  \"image_path\": \"/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/PuzzleTest/AlgoPuzzleVQA/data/images/think_dot/think_dot_0000.jpg\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# Copy images to subset_images directory\n",
    "subset_output_file = \"AlgoPuzzleVQA_train.jsonl\"\n",
    "# Create final JSONL with absolute image paths\n",
    "final_output_file = \"AlgoPuzzleVQA_train_run1_1K_v1_subset.jsonl\"\n",
    "base_dir = \"/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/PuzzleTest\"\n",
    "# absolute_subset_images_dir = os.path.join(base_dir, \"subset_images\")\n",
    "absolute_subset_images_dir = \"/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/PuzzleTest/AlgoPuzzleVQA/data\"\n",
    "\n",
    "print(f\"Creating final JSONL with absolute image paths: {final_output_file}\")\n",
    "\n",
    "with open(subset_output_file, 'r') as input_f, open(final_output_file, 'w') as output_f:\n",
    "    for line in input_f:\n",
    "        record = json.loads(line.strip())\n",
    "        \n",
    "        # Extract original filename\n",
    "        image_filename = record[\"image\"]\n",
    "        \n",
    "        # Create absolute path to the copied image\n",
    "        absolute_image_path = os.path.join(absolute_subset_images_dir, image_filename)\n",
    "        \n",
    "        # Add the image_path field\n",
    "        record[\"image_path\"] = absolute_image_path\n",
    "        \n",
    "        # Write the updated record\n",
    "        output_f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "print(f\"Created final output file: {final_output_file}\")\n",
    "\n",
    "# Show sample of final output\n",
    "with open(final_output_file, 'r') as f:\n",
    "    sample_record = json.loads(f.readline())\n",
    "    print(\"Sample final record:\")\n",
    "    print(json.dumps(sample_record, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating image paths in: ./prepared_jsonl/AlgoPuzzleVQA_train_run1_1K_v1_subset.jsonl\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "VALIDATION SUMMARY\n",
      "============================================================\n",
      "Total records processed: 900\n",
      "Valid PNG files: 900\n",
      "Invalid/missing files: 0\n",
      "Missing files: 0\n",
      "\n",
      "First 5 valid paths:\n",
      "  Line 1: /data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/PuzzleTest/AlgoPuzzleVQA/data/images/think_dot/think_dot_0000.jpg\n",
      "  Line 2: /data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/PuzzleTest/AlgoPuzzleVQA/data/images/think_dot/think_dot_0001.jpg\n",
      "  Line 3: /data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/PuzzleTest/AlgoPuzzleVQA/data/images/think_dot/think_dot_0002.jpg\n",
      "  Line 4: /data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/PuzzleTest/AlgoPuzzleVQA/data/images/think_dot/think_dot_0003.jpg\n",
      "  Line 5: /data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/PuzzleTest/AlgoPuzzleVQA/data/images/think_dot/think_dot_0004.jpg\n",
      "\n",
      "Success rate: 900/900 = 100.0%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def validate_image_paths(jsonl_file):\n",
    "    \"\"\"Validate all image paths in the JSONL file and check they correspond to actual PNG files.\"\"\"\n",
    "    \n",
    "    valid_paths = []\n",
    "    invalid_paths = []\n",
    "    missing_files = []\n",
    "    \n",
    "    print(f\"Validating image paths in: {jsonl_file}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Read the JSONL file\n",
    "    with open(jsonl_file, 'r') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            try:\n",
    "                record = json.loads(line.strip())\n",
    "                image_path = record.get('image_path')\n",
    "                \n",
    "                if not image_path:\n",
    "                    print(f\"Line {line_num}: Missing 'image_path' field\")\n",
    "                    invalid_paths.append((line_num, None, \"Missing image_path field\"))\n",
    "                    continue\n",
    "                \n",
    "                # Check if file exists\n",
    "                if os.path.exists(image_path):\n",
    "                    # Check if it's a PNG file\n",
    "                    if image_path.lower().endswith('.png') or image_path.lower().endswith('.jpg'):\n",
    "                        # Check if it's actually a file (not a directory)\n",
    "                        if os.path.isfile(image_path):\n",
    "                            valid_paths.append((line_num, image_path))\n",
    "                        else:\n",
    "                            print(f\"Line {line_num}: Path exists but is not a file: {image_path}\")\n",
    "                            invalid_paths.append((line_num, image_path, \"Not a file\"))\n",
    "                    else:\n",
    "                        print(f\"Line {line_num}: File exists but is not PNG: {image_path}\")\n",
    "                        invalid_paths.append((line_num, image_path, \"Not PNG file\"))\n",
    "                else:\n",
    "                    print(f\"Line {line_num}: File not found: {image_path}\")\n",
    "                    missing_files.append((line_num, image_path))\n",
    "                    invalid_paths.append((line_num, image_path, \"File not found\"))\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Line {line_num}: JSON decode error: {e}\")\n",
    "                invalid_paths.append((line_num, None, f\"JSON error: {e}\"))\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"VALIDATION SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total records processed: {len(valid_paths) + len(invalid_paths)}\")\n",
    "    print(f\"Valid PNG files: {len(valid_paths)}\")\n",
    "    print(f\"Invalid/missing files: {len(invalid_paths)}\")\n",
    "    print(f\"Missing files: {len(missing_files)}\")\n",
    "    \n",
    "    if valid_paths:\n",
    "        print(f\"\\nFirst 5 valid paths:\")\n",
    "        for line_num, path in valid_paths[:5]:\n",
    "            print(f\"  Line {line_num}: {path}\")\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"\\nFirst 5 missing files:\")\n",
    "        for line_num, path in missing_files[:5]:\n",
    "            print(f\"  Line {line_num}: {path}\")\n",
    "    \n",
    "    # Return results for further analysis\n",
    "    return {\n",
    "        'valid_paths': valid_paths,\n",
    "        'invalid_paths': invalid_paths,\n",
    "        'missing_files': missing_files,\n",
    "        'total_records': len(valid_paths) + len(invalid_paths)\n",
    "    }\n",
    "\n",
    "# Run the validation\n",
    "jsonl_file = \"./prepared_jsonl/AlgoPuzzleVQA_train_run1_1K_v1_subset.jsonl\"\n",
    "# jsonl_file = \"./prepared_jsonl/PuzzleVQA_train_run1_1K_v1_subset.jsonl\"\n",
    "results = validate_image_paths(jsonl_file)\n",
    "\n",
    "# Additional analysis\n",
    "print(f\"\\nSuccess rate: {len(results['valid_paths'])}/{results['total_records']} = {len(results['valid_paths'])/results['total_records']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmr_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
