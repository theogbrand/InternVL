{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"file-3b6e5721675449a98743b06d270c996b\",\n",
      "  \"bytes\": 1625,\n",
      "  \"created_at\": 1749631427,\n",
      "  \"filename\": \"example_batch_input.jsonl\",\n",
      "  \"object\": \"file\",\n",
      "  \"purpose\": \"batch\",\n",
      "  \"status\": \"processed\",\n",
      "  \"expires_at\": 1750841027,\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "    \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_API_KEY\"),  \n",
    "    api_version=\"2025-03-01-preview\",\n",
    "    azure_endpoint = \"https://aisg-sj.openai.azure.com/\" # o4-mini\n",
    "    # azure_endpoint = \"https://decla-mbncunfi-australiaeast.cognitiveservices.azure.com/\" # o3-mini\n",
    "    )\n",
    "\n",
    "# Upload a file with a purpose of \"batch\"\n",
    "file = client.files.create(\n",
    "  file=open(\"example_batch_input.jsonl\", \"rb\"), \n",
    "  purpose=\"batch\",\n",
    "  extra_body={\"expires_after\":{\"seconds\": 1209600, \"anchor\": \"created_at\"}} # Optional you can set to a number between 1209600-2592000. This is equivalent to 14-30 days\n",
    ")\n",
    "\n",
    "\n",
    "print(file.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File expiration: 2025-06-25 16:43:47\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "print(f\"File expiration: {datetime.datetime.fromtimestamp(file.expires_at) if file.expires_at is not None else 'Not set'}\")\n",
    "\n",
    "file_id = file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14\",\n",
      "  \"completion_window\": \"24h\",\n",
      "  \"created_at\": 1749631437,\n",
      "  \"endpoint\": \"/chat/completions\",\n",
      "  \"input_file_id\": \"file-3b6e5721675449a98743b06d270c996b\",\n",
      "  \"object\": \"batch\",\n",
      "  \"status\": \"validating\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"cancelling_at\": null,\n",
      "  \"completed_at\": null,\n",
      "  \"error_file_id\": \"\",\n",
      "  \"errors\": null,\n",
      "  \"expired_at\": null,\n",
      "  \"expires_at\": 1749717834,\n",
      "  \"failed_at\": null,\n",
      "  \"finalizing_at\": null,\n",
      "  \"in_progress_at\": null,\n",
      "  \"metadata\": null,\n",
      "  \"output_file_id\": \"\",\n",
      "  \"request_counts\": {\n",
      "    \"completed\": 0,\n",
      "    \"failed\": 0,\n",
      "    \"total\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Submit a batch job with the file\n",
    "batch_response = client.batches.create(\n",
    "    input_file_id=file_id,\n",
    "    endpoint=\"/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    extra_body={\"output_expires_after\":{\"seconds\": 1209600, \"anchor\": \"created_at\"}} # Optional you can set to a number between 1209600-2592000. This is equivalent to 14-30 days\n",
    ")\n",
    "\n",
    "\n",
    "# Save batch ID for later use\n",
    "batch_id = batch_response.id\n",
    "\n",
    "print(batch_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 16:44:58.510814 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: validating\n",
      "2025-06-11 16:45:59.458582 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: validating\n",
      "2025-06-11 16:47:00.425928 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: in_progress\n",
      "2025-06-11 16:48:01.360222 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: in_progress\n",
      "2025-06-11 16:49:02.342012 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: in_progress\n",
      "2025-06-11 16:50:03.274232 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: in_progress\n",
      "2025-06-11 16:51:04.211146 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: in_progress\n",
      "2025-06-11 16:52:05.197377 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: finalizing\n",
      "2025-06-11 16:53:06.181496 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime \n",
    "\n",
    "status = \"validating\"\n",
    "while status not in (\"completed\", \"failed\", \"canceled\"):\n",
    "    time.sleep(60)\n",
    "    batch_response = client.batches.retrieve(batch_id)\n",
    "    status = batch_response.status\n",
    "    print(f\"{datetime.datetime.now()} Batch Id: {batch_id},  Status: {status}\")\n",
    "\n",
    "if batch_response.status == \"failed\":\n",
    "    for error in batch_response.errors.data:  \n",
    "        print(f\"Error code {error.code} Message {error.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"custom_id\": \"request-1\",\n",
      "  \"response\": {\n",
      "    \"body\": {\n",
      "      \"choices\": [\n",
      "        {\n",
      "          \"content_filter_results\": {\n",
      "            \"hate\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"self_harm\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"sexual\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"violence\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            }\n",
      "          },\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"index\": 0,\n",
      "          \"logprobs\": null,\n",
      "          \"message\": {\n",
      "            \"annotations\": [],\n",
      "            \"content\": \"It\\u2019s the \\u201csmiling face with heart-eyes\\u201d emoji. A round, bright yellow face with a big, enthusiastic grin and two red hearts replacing its eyes\\u2014used to show love, adoration, or delight.\",\n",
      "            \"refusal\": null,\n",
      "            \"role\": \"assistant\"\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"created\": 1749631683,\n",
      "      \"id\": \"chatcmpl-BhBPnHwTF2iPyE5f5mJQ6RwItMjTx\",\n",
      "      \"model\": \"o4-mini-2025-04-16\",\n",
      "      \"object\": \"chat.completion\",\n",
      "      \"prompt_filter_results\": [\n",
      "        {\n",
      "          \"prompt_index\": 0,\n",
      "          \"content_filter_result\": {}\n",
      "        }\n",
      "      ],\n",
      "      \"system_fingerprint\": null,\n",
      "      \"usage\": {\n",
      "        \"completion_tokens\": 128,\n",
      "        \"completion_tokens_details\": {\n",
      "          \"accepted_prediction_tokens\": 0,\n",
      "          \"audio_tokens\": 0,\n",
      "          \"reasoning_tokens\": 64,\n",
      "          \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens\": 22,\n",
      "        \"prompt_tokens_details\": {\n",
      "          \"audio_tokens\": 0,\n",
      "          \"cached_tokens\": 0\n",
      "        },\n",
      "        \"total_tokens\": 150\n",
      "      }\n",
      "    },\n",
      "    \"request_id\": \"843d502c-6665-4058-b3c8-98f24f75dabe\",\n",
      "    \"status_code\": 200\n",
      "  },\n",
      "  \"error\": null\n",
      "}\n",
      "\n",
      "Saved 1 verification results to verification_results.json\n",
      "All samples processed successfully with status_code 200\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "output_file_id = batch_response.output_file_id\n",
    "\n",
    "if not output_file_id:\n",
    "    output_file_id = batch_response.error_file_id\n",
    "\n",
    "verification_results = []\n",
    "error_sample_ids = []\n",
    "\n",
    "if output_file_id:\n",
    "    file_response = client.files.content(output_file_id)\n",
    "    raw_responses = file_response.text.strip().split('\\n')  \n",
    "\n",
    "    for raw_response in raw_responses:  \n",
    "        json_response = json.loads(raw_response)  \n",
    "        \n",
    "        # Check for error status codes\n",
    "        if json_response[\"response\"][\"status_code\"] != 200:\n",
    "            error_sample_ids.append(json_response[\"custom_id\"])\n",
    "            continue\n",
    "        \n",
    "        # Create new JSON format with desired schema for successful responses\n",
    "        verification_entry = {\n",
    "            \"custom_id\": json_response[\"custom_id\"],\n",
    "            \"verification_response\": json_response[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "        }\n",
    "        \n",
    "        verification_results.append(verification_entry)\n",
    "        \n",
    "        # Optional: print original for debugging\n",
    "        formatted_json = json.dumps(json_response, indent=2)  \n",
    "        print(formatted_json)\n",
    "\n",
    "# Save verification results to file\n",
    "with open('verification_results.json', 'w') as f:\n",
    "    json.dump(verification_results, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved {len(verification_results)} verification results to verification_results.json\")\n",
    "\n",
    "if error_sample_ids:\n",
    "    print(f\"Error sample IDs with status_code != 200: {error_sample_ids}\")\n",
    "else:\n",
    "    print(\"All samples processed successfully with status_code 200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14\",\n",
      "      \"completion_window\": \"24h\",\n",
      "      \"created_at\": 1749631437,\n",
      "      \"endpoint\": \"/chat/completions\",\n",
      "      \"input_file_id\": \"file-3b6e5721675449a98743b06d270c996b\",\n",
      "      \"object\": \"batch\",\n",
      "      \"status\": \"completed\",\n",
      "      \"cancelled_at\": null,\n",
      "      \"cancelling_at\": null,\n",
      "      \"completed_at\": 1749631958,\n",
      "      \"error_file_id\": null,\n",
      "      \"errors\": null,\n",
      "      \"expired_at\": null,\n",
      "      \"expires_at\": 1749717834,\n",
      "      \"failed_at\": null,\n",
      "      \"finalizing_at\": 1749631887,\n",
      "      \"in_progress_at\": 1749631640,\n",
      "      \"metadata\": null,\n",
      "      \"output_file_id\": \"file-da79c320-ee92-40f9-9167-86b270259bc9\",\n",
      "      \"request_counts\": {\n",
      "        \"completed\": 1,\n",
      "        \"failed\": 0,\n",
      "        \"total\": 1\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"batch_8d9364c9-7bba-470e-b80d-a6278e99a62e\",\n",
      "      \"completion_window\": \"24h\",\n",
      "      \"created_at\": 1749622944,\n",
      "      \"endpoint\": \"/chat/completions\",\n",
      "      \"input_file_id\": \"file-7ba74b86dcb14621be65d4095c4ed1ce\",\n",
      "      \"object\": \"batch\",\n",
      "      \"status\": \"completed\",\n",
      "      \"cancelled_at\": null,\n",
      "      \"cancelling_at\": null,\n",
      "      \"completed_at\": 1749623742,\n",
      "      \"error_file_id\": null,\n",
      "      \"errors\": null,\n",
      "      \"expired_at\": null,\n",
      "      \"expires_at\": 1749709341,\n",
      "      \"failed_at\": null,\n",
      "      \"finalizing_at\": 1749623676,\n",
      "      \"in_progress_at\": 1749623199,\n",
      "      \"metadata\": null,\n",
      "      \"output_file_id\": \"file-ad5fb152-3cc1-4094-8591-67e7e94fd419\",\n",
      "      \"request_counts\": {\n",
      "        \"completed\": 1,\n",
      "        \"failed\": 0,\n",
      "        \"total\": 1\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"batch_350476ad-c6e5-4fd7-87a7-fe0ddde4c794\",\n",
      "      \"completion_window\": \"24h\",\n",
      "      \"created_at\": 1749622329,\n",
      "      \"endpoint\": \"/chat/completions\",\n",
      "      \"input_file_id\": \"file-da50b8e98976444eb2e50163a3184320\",\n",
      "      \"object\": \"batch\",\n",
      "      \"status\": \"completed\",\n",
      "      \"cancelled_at\": null,\n",
      "      \"cancelling_at\": null,\n",
      "      \"completed_at\": 1749622923,\n",
      "      \"error_file_id\": \"file-b07f3b18-8594-4cfd-a5f0-6dd66f556786\",\n",
      "      \"errors\": null,\n",
      "      \"expired_at\": null,\n",
      "      \"expires_at\": 1749708726,\n",
      "      \"failed_at\": null,\n",
      "      \"finalizing_at\": 1749622853,\n",
      "      \"in_progress_at\": 1749622492,\n",
      "      \"metadata\": null,\n",
      "      \"output_file_id\": null,\n",
      "      \"request_counts\": {\n",
      "        \"completed\": 0,\n",
      "        \"failed\": 1,\n",
      "        \"total\": 1\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"batch_f0c5f4c8-5141-49bf-bb57-c86f5b91df92\",\n",
      "      \"completion_window\": \"24h\",\n",
      "      \"created_at\": 1749619394,\n",
      "      \"endpoint\": \"/chat/completions\",\n",
      "      \"input_file_id\": \"file-222b2efcbd6446f38cf47f710951425b\",\n",
      "      \"object\": \"batch\",\n",
      "      \"status\": \"completed\",\n",
      "      \"cancelled_at\": null,\n",
      "      \"cancelling_at\": null,\n",
      "      \"completed_at\": 1749620136,\n",
      "      \"error_file_id\": \"file-1a50b3e2-2722-4e1e-b5d7-6ada3b672070\",\n",
      "      \"errors\": null,\n",
      "      \"expired_at\": null,\n",
      "      \"expires_at\": 1749705792,\n",
      "      \"failed_at\": null,\n",
      "      \"finalizing_at\": 1749620071,\n",
      "      \"in_progress_at\": 1749619584,\n",
      "      \"metadata\": null,\n",
      "      \"output_file_id\": null,\n",
      "      \"request_counts\": {\n",
      "        \"completed\": 0,\n",
      "        \"failed\": 1,\n",
      "        \"total\": 1\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"has_more\": false,\n",
      "  \"first_id\": \"batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14\",\n",
      "  \"last_id\": \"batch_f0c5f4c8-5141-49bf-bb57-c86f5b91df92\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(client.batches.list().model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch(id='batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14', completion_window='24h', created_at=1749631437, endpoint='/chat/completions', input_file_id='file-3b6e5721675449a98743b06d270c996b', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1749631958, error_file_id=None, errors=None, expired_at=None, expires_at=1749717834, failed_at=None, finalizing_at=1749631887, in_progress_at=1749631640, metadata=None, output_file_id='file-da79c320-ee92-40f9-9167-86b270259bc9', request_counts=BatchRequestCounts(completed=1, failed=0, total=1)), Batch(id='batch_8d9364c9-7bba-470e-b80d-a6278e99a62e', completion_window='24h', created_at=1749622944, endpoint='/chat/completions', input_file_id='file-7ba74b86dcb14621be65d4095c4ed1ce', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1749623742, error_file_id=None, errors=None, expired_at=None, expires_at=1749709341, failed_at=None, finalizing_at=1749623676, in_progress_at=1749623199, metadata=None, output_file_id='file-ad5fb152-3cc1-4094-8591-67e7e94fd419', request_counts=BatchRequestCounts(completed=1, failed=0, total=1)), Batch(id='batch_350476ad-c6e5-4fd7-87a7-fe0ddde4c794', completion_window='24h', created_at=1749622329, endpoint='/chat/completions', input_file_id='file-da50b8e98976444eb2e50163a3184320', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1749622923, error_file_id='file-b07f3b18-8594-4cfd-a5f0-6dd66f556786', errors=None, expired_at=None, expires_at=1749708726, failed_at=None, finalizing_at=1749622853, in_progress_at=1749622492, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=1, total=1)), Batch(id='batch_f0c5f4c8-5141-49bf-bb57-c86f5b91df92', completion_window='24h', created_at=1749619394, endpoint='/chat/completions', input_file_id='file-222b2efcbd6446f38cf47f710951425b', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1749620136, error_file_id='file-1a50b3e2-2722-4e1e-b5d7-6ada3b672070', errors=None, expired_at=None, expires_at=1749705792, failed_at=None, finalizing_at=1749620071, in_progress_at=1749619584, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=1, total=1))]\n"
     ]
    }
   ],
   "source": [
    "all_jobs = []\n",
    "# Automatically fetches more pages as needed.\n",
    "for job in client.batches.list(\n",
    "    limit=20,\n",
    "):\n",
    "    # Do something with job here\n",
    "    all_jobs.append(job)\n",
    "print(all_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import BadRequestError\n",
    "\n",
    "max_retries = 10\n",
    "retries = 0\n",
    "initial_delay = 5\n",
    "delay = initial_delay\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        batch_response = client.batches.create(\n",
    "            input_file_id=file_id,\n",
    "            endpoint=\"/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "        )\n",
    "        \n",
    "        # Save batch ID for later use\n",
    "        batch_id = batch_response.id\n",
    "        \n",
    "        print(f\"✅ Batch created successfully after {retries} retries\")\n",
    "        print(batch_response.model_dump_json(indent=2))\n",
    "        break  \n",
    "        \n",
    "    except BadRequestError as e:\n",
    "        error_message = str(e)\n",
    "        \n",
    "        # Check if it's a token limit error\n",
    "        if 'token_limit_exceeded' in error_message:\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                print(f\"❌ Maximum retries ({max_retries}) reached. Giving up.\")\n",
    "                raise\n",
    "            \n",
    "            print(f\"⏳ Token limit exceeded. Waiting {delay} seconds before retry {retries}/{max_retries}...\")\n",
    "            time.sleep(delay)\n",
    "            \n",
    "            # Exponential backoff - increase delay for next attempt\n",
    "            delay *= 2\n",
    "        else:\n",
    "            # If it's a different error, raise it immediately\n",
    "            print(f\"❌ Encountered non-token limit error: {error_message}\")\n",
    "            raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmr_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
