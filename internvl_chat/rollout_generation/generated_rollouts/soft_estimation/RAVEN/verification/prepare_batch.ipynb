{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"file-7ba74b86dcb14621be65d4095c4ed1ce\",\n",
      "  \"bytes\": 1625,\n",
      "  \"created_at\": 1749622941,\n",
      "  \"filename\": \"example_batch_input.jsonl\",\n",
      "  \"object\": \"file\",\n",
      "  \"purpose\": \"batch\",\n",
      "  \"status\": \"processed\",\n",
      "  \"expires_at\": 1750832541,\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "    \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_API_KEY\"),  \n",
    "    api_version=\"2025-03-01-preview\",\n",
    "    azure_endpoint = \"https://aisg-sj.openai.azure.com/\"\n",
    "    # azure_endpoint = \"https://decla-mbncunfi-australiaeast.cognitiveservices.azure.com/\" # o3-mini\n",
    "    )\n",
    "\n",
    "# Upload a file with a purpose of \"batch\"\n",
    "file = client.files.create(\n",
    "  file=open(\"example_batch_input.jsonl\", \"rb\"), \n",
    "  purpose=\"batch\",\n",
    "  extra_body={\"expires_after\":{\"seconds\": 1209600, \"anchor\": \"created_at\"}} # Optional you can set to a number between 1209600-2592000. This is equivalent to 14-30 days\n",
    ")\n",
    "\n",
    "\n",
    "print(file.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File expiration: 2025-06-25 14:22:21\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "print(f\"File expiration: {datetime.datetime.fromtimestamp(file.expires_at) if file.expires_at is not None else 'Not set'}\")\n",
    "\n",
    "file_id = file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"batch_8d9364c9-7bba-470e-b80d-a6278e99a62e\",\n",
      "  \"completion_window\": \"24h\",\n",
      "  \"created_at\": 1749622944,\n",
      "  \"endpoint\": \"/chat/completions\",\n",
      "  \"input_file_id\": \"file-7ba74b86dcb14621be65d4095c4ed1ce\",\n",
      "  \"object\": \"batch\",\n",
      "  \"status\": \"validating\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"cancelling_at\": null,\n",
      "  \"completed_at\": null,\n",
      "  \"error_file_id\": \"\",\n",
      "  \"errors\": null,\n",
      "  \"expired_at\": null,\n",
      "  \"expires_at\": 1749709341,\n",
      "  \"failed_at\": null,\n",
      "  \"finalizing_at\": null,\n",
      "  \"in_progress_at\": null,\n",
      "  \"metadata\": null,\n",
      "  \"output_file_id\": \"\",\n",
      "  \"request_counts\": {\n",
      "    \"completed\": 0,\n",
      "    \"failed\": 0,\n",
      "    \"total\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Submit a batch job with the file\n",
    "batch_response = client.batches.create(\n",
    "    input_file_id=file_id,\n",
    "    endpoint=\"/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    extra_body={\"output_expires_after\":{\"seconds\": 1209600, \"anchor\": \"created_at\"}} # Optional you can set to a number between 1209600-2592000. This is equivalent to 14-30 days\n",
    ")\n",
    "\n",
    "\n",
    "# Save batch ID for later use\n",
    "batch_id = batch_response.id\n",
    "\n",
    "print(batch_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:43:52.267612 Batch Id: batch_8d9364c9-7bba-470e-b80d-a6278e99a62e,  Status: completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime \n",
    "\n",
    "status = \"validating\"\n",
    "while status not in (\"completed\", \"failed\", \"canceled\"):\n",
    "    time.sleep(60)\n",
    "    batch_response = client.batches.retrieve(batch_id)\n",
    "    status = batch_response.status\n",
    "    print(f\"{datetime.datetime.now()} Batch Id: {batch_id},  Status: {status}\")\n",
    "\n",
    "if batch_response.status == \"failed\":\n",
    "    for error in batch_response.errors.data:  \n",
    "        print(f\"Error code {error.code} Message {error.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"custom_id\": \"request-1\",\n",
      "  \"response\": {\n",
      "    \"body\": {\n",
      "      \"choices\": [\n",
      "        {\n",
      "          \"content_filter_results\": {\n",
      "            \"hate\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"self_harm\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"sexual\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"violence\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            }\n",
      "          },\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"index\": 0,\n",
      "          \"logprobs\": null,\n",
      "          \"message\": {\n",
      "            \"annotations\": [],\n",
      "            \"content\": \"It\\u2019s a yellow, round \\u201csmiley\\u201d face with an open-mouthed grin and two red hearts in place of its eyes. It conveys adoration, love, infatuation or enthusiastic approval.\",\n",
      "            \"refusal\": null,\n",
      "            \"role\": \"assistant\"\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"created\": 1749623288,\n",
      "      \"id\": \"chatcmpl-Bh9EOphKQb8cnhdlONyEhPyWq9NoI\",\n",
      "      \"model\": \"o4-mini-2025-04-16\",\n",
      "      \"object\": \"chat.completion\",\n",
      "      \"prompt_filter_results\": [\n",
      "        {\n",
      "          \"prompt_index\": 0,\n",
      "          \"content_filter_result\": {}\n",
      "        }\n",
      "      ],\n",
      "      \"system_fingerprint\": null,\n",
      "      \"usage\": {\n",
      "        \"completion_tokens\": 126,\n",
      "        \"completion_tokens_details\": {\n",
      "          \"accepted_prediction_tokens\": 0,\n",
      "          \"audio_tokens\": 0,\n",
      "          \"reasoning_tokens\": 64,\n",
      "          \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens\": 22,\n",
      "        \"prompt_tokens_details\": {\n",
      "          \"audio_tokens\": 0,\n",
      "          \"cached_tokens\": 0\n",
      "        },\n",
      "        \"total_tokens\": 148\n",
      "      }\n",
      "    },\n",
      "    \"request_id\": \"5110d181-6d06-427e-acd8-61a9ccf91175\",\n",
      "    \"status_code\": 200\n",
      "  },\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "output_file_id = batch_response.output_file_id\n",
    "\n",
    "if not output_file_id:\n",
    "    output_file_id = batch_response.error_file_id\n",
    "\n",
    "if output_file_id:\n",
    "    file_response = client.files.content(output_file_id)\n",
    "    raw_responses = file_response.text.strip().split('\\n')  \n",
    "\n",
    "    for raw_response in raw_responses:  \n",
    "        json_response = json.loads(raw_response)  \n",
    "        formatted_json = json.dumps(json_response, indent=2)  \n",
    "        print(formatted_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch(id='batch_8d9364c9-7bba-470e-b80d-a6278e99a62e', completion_window='24h', created_at=1749622944, endpoint='/chat/completions', input_file_id='file-7ba74b86dcb14621be65d4095c4ed1ce', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1749623742, error_file_id=None, errors=None, expired_at=None, expires_at=1749709341, failed_at=None, finalizing_at=1749623676, in_progress_at=1749623199, metadata=None, output_file_id='file-ad5fb152-3cc1-4094-8591-67e7e94fd419', request_counts=BatchRequestCounts(completed=1, failed=0, total=1)), Batch(id='batch_350476ad-c6e5-4fd7-87a7-fe0ddde4c794', completion_window='24h', created_at=1749622329, endpoint='/chat/completions', input_file_id='file-da50b8e98976444eb2e50163a3184320', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1749622923, error_file_id='file-b07f3b18-8594-4cfd-a5f0-6dd66f556786', errors=None, expired_at=None, expires_at=1749708726, failed_at=None, finalizing_at=1749622853, in_progress_at=1749622492, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=1, total=1)), Batch(id='batch_f0c5f4c8-5141-49bf-bb57-c86f5b91df92', completion_window='24h', created_at=1749619394, endpoint='/chat/completions', input_file_id='file-222b2efcbd6446f38cf47f710951425b', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1749620136, error_file_id='file-1a50b3e2-2722-4e1e-b5d7-6ada3b672070', errors=None, expired_at=None, expires_at=1749705792, failed_at=None, finalizing_at=1749620071, in_progress_at=1749619584, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=1, total=1))]\n"
     ]
    }
   ],
   "source": [
    "all_jobs = []\n",
    "# Automatically fetches more pages as needed.\n",
    "for job in client.batches.list(\n",
    "    limit=20,\n",
    "):\n",
    "    # Do something with job here\n",
    "    all_jobs.append(job)\n",
    "print(all_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import BadRequestError\n",
    "\n",
    "max_retries = 10\n",
    "retries = 0\n",
    "initial_delay = 5\n",
    "delay = initial_delay\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        batch_response = client.batches.create(\n",
    "            input_file_id=file_id,\n",
    "            endpoint=\"/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "        )\n",
    "        \n",
    "        # Save batch ID for later use\n",
    "        batch_id = batch_response.id\n",
    "        \n",
    "        print(f\"✅ Batch created successfully after {retries} retries\")\n",
    "        print(batch_response.model_dump_json(indent=2))\n",
    "        break  \n",
    "        \n",
    "    except BadRequestError as e:\n",
    "        error_message = str(e)\n",
    "        \n",
    "        # Check if it's a token limit error\n",
    "        if 'token_limit_exceeded' in error_message:\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                print(f\"❌ Maximum retries ({max_retries}) reached. Giving up.\")\n",
    "                raise\n",
    "            \n",
    "            print(f\"⏳ Token limit exceeded. Waiting {delay} seconds before retry {retries}/{max_retries}...\")\n",
    "            time.sleep(delay)\n",
    "            \n",
    "            # Exponential backoff - increase delay for next attempt\n",
    "            delay *= 2\n",
    "        else:\n",
    "            # If it's a different error, raise it immediately\n",
    "            print(f\"❌ Encountered non-token limit error: {error_message}\")\n",
    "            raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmr_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
