{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"file-57387d335dac433ba0d44591d8e1e1c5\",\n",
      "  \"bytes\": 12861601,\n",
      "  \"created_at\": 1749635885,\n",
      "  \"filename\": \"batch_0001.jsonl\",\n",
      "  \"object\": \"file\",\n",
      "  \"purpose\": \"batch\",\n",
      "  \"status\": \"processed\",\n",
      "  \"expires_at\": 1750845485,\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "    \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_API_KEY\"),  \n",
    "    api_version=\"2025-03-01-preview\",\n",
    "    azure_endpoint = \"https://aisg-sj.openai.azure.com/\" # o4-mini\n",
    "    # azure_endpoint = \"https://decla-mbncunfi-australiaeast.cognitiveservices.azure.com/\" # o3-mini\n",
    "    )\n",
    "\n",
    "# Upload a file with a purpose of \"batch\"\n",
    "file = client.files.create(\n",
    "  file=open(\"/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/generated_rollouts/soft_estimation/RAVEN/verification/verification_pipeline_outputs/verification_batches/batch_0001.jsonl\", \"rb\"), \n",
    "  purpose=\"batch\",\n",
    "  extra_body={\"expires_after\":{\"seconds\": 1209600, \"anchor\": \"created_at\"}} # Optional you can set to a number between 1209600-2592000. This is equivalent to 14-30 days\n",
    ")\n",
    "\n",
    "\n",
    "print(file.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File expiration: 2025-06-25 17:58:05\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "print(f\"File expiration: {datetime.datetime.fromtimestamp(file.expires_at) if file.expires_at is not None else 'Not set'}\")\n",
    "\n",
    "file_id = file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'errors': {'data': [{'code': 'duplicate_custom_id', 'message': \"The line '2' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 2, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '4' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 4, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '8' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 8, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '10' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 10, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '12' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 12, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '13' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 13, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '15' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 15, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '17' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 17, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '20' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 20, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '21' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 21, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '22' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 22, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '24' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 24, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '25' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 25, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '27' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 27, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '29' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 29, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '31' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 31, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '32' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 32, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '33' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 33, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '34' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 34, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '35' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 35, 'param': None}], 'object': 'list'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Submit a batch job with the file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m batch_response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_file_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompletion_window\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m24h\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_expires_after\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseconds\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1209600\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manchor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcreated_at\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Optional you can set to a number between 1209600-2592000. This is equivalent to 14-30 days\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Save batch ID for later use\u001b[39;00m\n\u001b[32m     11\u001b[39m batch_id = batch_response.id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/mmr_processing/lib/python3.12/site-packages/openai/resources/batches.py:96\u001b[39m, in \u001b[36mBatches.create\u001b[39m\u001b[34m(self, completion_window, endpoint, input_file_id, metadata, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m     46\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     47\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m     58\u001b[39m ) -> Batch:\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[33;03m    Creates and executes a batch from an uploaded file of requests\u001b[39;00m\n\u001b[32m     61\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/batches\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompletion_window\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletion_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mendpoint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_file_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_file_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBatchCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/mmr_processing/lib/python3.12/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/mmr_processing/lib/python3.12/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'errors': {'data': [{'code': 'duplicate_custom_id', 'message': \"The line '2' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 2, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '4' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 4, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '8' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 8, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '10' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 10, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '12' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 12, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '13' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 13, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '15' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 15, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '17' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 17, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '20' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 20, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '21' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 21, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '22' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 22, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '24' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 24, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '25' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 25, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '27' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 27, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '29' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 29, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '31' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 31, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '32' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 32, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '33' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 33, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '34' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 34, 'param': None}, {'code': 'duplicate_custom_id', 'message': \"The line '35' contains a duplicate custom_id present in another request. Please ensure that the custom_id parameter is unique for each request in the batch. Learn more: https://aka.ms/aoai_batch/errors.\", 'line': 35, 'param': None}], 'object': 'list'}}"
     ]
    }
   ],
   "source": [
    "# Submit a batch job with the file\n",
    "batch_response = client.batches.create(\n",
    "    input_file_id=file_id,\n",
    "    endpoint=\"/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    extra_body={\"output_expires_after\":{\"seconds\": 1209600, \"anchor\": \"created_at\"}} # Optional you can set to a number between 1209600-2592000. This is equivalent to 14-30 days\n",
    ")\n",
    "\n",
    "\n",
    "# Save batch ID for later use\n",
    "batch_id = batch_response.id\n",
    "\n",
    "print(batch_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 16:44:58.510814 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: validating\n",
      "2025-06-11 16:45:59.458582 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: validating\n",
      "2025-06-11 16:47:00.425928 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: in_progress\n",
      "2025-06-11 16:48:01.360222 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: in_progress\n",
      "2025-06-11 16:49:02.342012 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: in_progress\n",
      "2025-06-11 16:50:03.274232 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: in_progress\n",
      "2025-06-11 16:51:04.211146 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: in_progress\n",
      "2025-06-11 16:52:05.197377 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: finalizing\n",
      "2025-06-11 16:53:06.181496 Batch Id: batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14,  Status: completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime \n",
    "\n",
    "status = \"validating\"\n",
    "while status not in (\"completed\", \"failed\", \"canceled\"):\n",
    "    time.sleep(60)\n",
    "    batch_response = client.batches.retrieve(batch_id)\n",
    "    status = batch_response.status\n",
    "    print(f\"{datetime.datetime.now()} Batch Id: {batch_id},  Status: {status}\")\n",
    "\n",
    "if batch_response.status == \"failed\":\n",
    "    for error in batch_response.errors.data:  \n",
    "        print(f\"Error code {error.code} Message {error.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m output_file_id = \u001b[43mbatch_response\u001b[49m.output_file_id\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_file_id:\n\u001b[32m      6\u001b[39m     output_file_id = batch_response.error_file_id\n",
      "\u001b[31mNameError\u001b[39m: name 'batch_response' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "output_file_id = batch_response.output_file_id\n",
    "\n",
    "if not output_file_id:\n",
    "    output_file_id = batch_response.error_file_id\n",
    "\n",
    "verification_results = []\n",
    "error_sample_ids = []\n",
    "\n",
    "if output_file_id:\n",
    "    file_response = client.files.content(output_file_id)\n",
    "    raw_responses = file_response.text.strip().split('\\n')  \n",
    "\n",
    "    for raw_response in raw_responses:  \n",
    "        json_response = json.loads(raw_response)  \n",
    "        \n",
    "        # Check for error status codes\n",
    "        if json_response[\"response\"][\"status_code\"] != 200:\n",
    "            error_sample_ids.append(json_response[\"custom_id\"])\n",
    "            continue\n",
    "        \n",
    "        # Create new JSON format with desired schema for successful responses\n",
    "        verification_entry = {\n",
    "            \"custom_id\": json_response[\"custom_id\"],\n",
    "            \"verification_response\": json_response[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "        }\n",
    "        \n",
    "        verification_results.append(verification_entry)\n",
    "        \n",
    "        # Optional: print original for debugging\n",
    "        formatted_json = json.dumps(json_response, indent=2)  \n",
    "        print(formatted_json)\n",
    "\n",
    "# Save verification results to file\n",
    "with open('verification_results.json', 'w') as f:\n",
    "    json.dump(verification_results, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved {len(verification_results)} verification results to verification_results.json\")\n",
    "\n",
    "if error_sample_ids:\n",
    "    print(f\"Error sample IDs with status_code != 200: {error_sample_ids}\")\n",
    "else:\n",
    "    print(\"All samples processed successfully with status_code 200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14\",\n",
      "      \"completion_window\": \"24h\",\n",
      "      \"created_at\": 1749631437,\n",
      "      \"endpoint\": \"/chat/completions\",\n",
      "      \"input_file_id\": \"file-3b6e5721675449a98743b06d270c996b\",\n",
      "      \"object\": \"batch\",\n",
      "      \"status\": \"completed\",\n",
      "      \"cancelled_at\": null,\n",
      "      \"cancelling_at\": null,\n",
      "      \"completed_at\": 1749631958,\n",
      "      \"error_file_id\": null,\n",
      "      \"errors\": null,\n",
      "      \"expired_at\": null,\n",
      "      \"expires_at\": 1749717834,\n",
      "      \"failed_at\": null,\n",
      "      \"finalizing_at\": 1749631887,\n",
      "      \"in_progress_at\": 1749631640,\n",
      "      \"metadata\": null,\n",
      "      \"output_file_id\": \"file-da79c320-ee92-40f9-9167-86b270259bc9\",\n",
      "      \"request_counts\": {\n",
      "        \"completed\": 1,\n",
      "        \"failed\": 0,\n",
      "        \"total\": 1\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"batch_8d9364c9-7bba-470e-b80d-a6278e99a62e\",\n",
      "      \"completion_window\": \"24h\",\n",
      "      \"created_at\": 1749622944,\n",
      "      \"endpoint\": \"/chat/completions\",\n",
      "      \"input_file_id\": \"file-7ba74b86dcb14621be65d4095c4ed1ce\",\n",
      "      \"object\": \"batch\",\n",
      "      \"status\": \"completed\",\n",
      "      \"cancelled_at\": null,\n",
      "      \"cancelling_at\": null,\n",
      "      \"completed_at\": 1749623742,\n",
      "      \"error_file_id\": null,\n",
      "      \"errors\": null,\n",
      "      \"expired_at\": null,\n",
      "      \"expires_at\": 1749709341,\n",
      "      \"failed_at\": null,\n",
      "      \"finalizing_at\": 1749623676,\n",
      "      \"in_progress_at\": 1749623199,\n",
      "      \"metadata\": null,\n",
      "      \"output_file_id\": \"file-ad5fb152-3cc1-4094-8591-67e7e94fd419\",\n",
      "      \"request_counts\": {\n",
      "        \"completed\": 1,\n",
      "        \"failed\": 0,\n",
      "        \"total\": 1\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"batch_350476ad-c6e5-4fd7-87a7-fe0ddde4c794\",\n",
      "      \"completion_window\": \"24h\",\n",
      "      \"created_at\": 1749622329,\n",
      "      \"endpoint\": \"/chat/completions\",\n",
      "      \"input_file_id\": \"file-da50b8e98976444eb2e50163a3184320\",\n",
      "      \"object\": \"batch\",\n",
      "      \"status\": \"completed\",\n",
      "      \"cancelled_at\": null,\n",
      "      \"cancelling_at\": null,\n",
      "      \"completed_at\": 1749622923,\n",
      "      \"error_file_id\": \"file-b07f3b18-8594-4cfd-a5f0-6dd66f556786\",\n",
      "      \"errors\": null,\n",
      "      \"expired_at\": null,\n",
      "      \"expires_at\": 1749708726,\n",
      "      \"failed_at\": null,\n",
      "      \"finalizing_at\": 1749622853,\n",
      "      \"in_progress_at\": 1749622492,\n",
      "      \"metadata\": null,\n",
      "      \"output_file_id\": null,\n",
      "      \"request_counts\": {\n",
      "        \"completed\": 0,\n",
      "        \"failed\": 1,\n",
      "        \"total\": 1\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"batch_f0c5f4c8-5141-49bf-bb57-c86f5b91df92\",\n",
      "      \"completion_window\": \"24h\",\n",
      "      \"created_at\": 1749619394,\n",
      "      \"endpoint\": \"/chat/completions\",\n",
      "      \"input_file_id\": \"file-222b2efcbd6446f38cf47f710951425b\",\n",
      "      \"object\": \"batch\",\n",
      "      \"status\": \"completed\",\n",
      "      \"cancelled_at\": null,\n",
      "      \"cancelling_at\": null,\n",
      "      \"completed_at\": 1749620136,\n",
      "      \"error_file_id\": \"file-1a50b3e2-2722-4e1e-b5d7-6ada3b672070\",\n",
      "      \"errors\": null,\n",
      "      \"expired_at\": null,\n",
      "      \"expires_at\": 1749705792,\n",
      "      \"failed_at\": null,\n",
      "      \"finalizing_at\": 1749620071,\n",
      "      \"in_progress_at\": 1749619584,\n",
      "      \"metadata\": null,\n",
      "      \"output_file_id\": null,\n",
      "      \"request_counts\": {\n",
      "        \"completed\": 0,\n",
      "        \"failed\": 1,\n",
      "        \"total\": 1\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"has_more\": false,\n",
      "  \"first_id\": \"batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14\",\n",
      "  \"last_id\": \"batch_f0c5f4c8-5141-49bf-bb57-c86f5b91df92\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(client.batches.list().model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch(id='batch_ade6952d-64bb-4d1d-ab4c-57b1dbdc9d14', completion_window='24h', created_at=1749631437, endpoint='/chat/completions', input_file_id='file-3b6e5721675449a98743b06d270c996b', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1749631958, error_file_id=None, errors=None, expired_at=None, expires_at=1749717834, failed_at=None, finalizing_at=1749631887, in_progress_at=1749631640, metadata=None, output_file_id='file-da79c320-ee92-40f9-9167-86b270259bc9', request_counts=BatchRequestCounts(completed=1, failed=0, total=1)), Batch(id='batch_8d9364c9-7bba-470e-b80d-a6278e99a62e', completion_window='24h', created_at=1749622944, endpoint='/chat/completions', input_file_id='file-7ba74b86dcb14621be65d4095c4ed1ce', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1749623742, error_file_id=None, errors=None, expired_at=None, expires_at=1749709341, failed_at=None, finalizing_at=1749623676, in_progress_at=1749623199, metadata=None, output_file_id='file-ad5fb152-3cc1-4094-8591-67e7e94fd419', request_counts=BatchRequestCounts(completed=1, failed=0, total=1)), Batch(id='batch_350476ad-c6e5-4fd7-87a7-fe0ddde4c794', completion_window='24h', created_at=1749622329, endpoint='/chat/completions', input_file_id='file-da50b8e98976444eb2e50163a3184320', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1749622923, error_file_id='file-b07f3b18-8594-4cfd-a5f0-6dd66f556786', errors=None, expired_at=None, expires_at=1749708726, failed_at=None, finalizing_at=1749622853, in_progress_at=1749622492, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=1, total=1)), Batch(id='batch_f0c5f4c8-5141-49bf-bb57-c86f5b91df92', completion_window='24h', created_at=1749619394, endpoint='/chat/completions', input_file_id='file-222b2efcbd6446f38cf47f710951425b', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1749620136, error_file_id='file-1a50b3e2-2722-4e1e-b5d7-6ada3b672070', errors=None, expired_at=None, expires_at=1749705792, failed_at=None, finalizing_at=1749620071, in_progress_at=1749619584, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=1, total=1))]\n"
     ]
    }
   ],
   "source": [
    "all_jobs = []\n",
    "# Automatically fetches more pages as needed.\n",
    "for job in client.batches.list(\n",
    "    limit=20,\n",
    "):\n",
    "    # Do something with job here\n",
    "    all_jobs.append(job)\n",
    "print(all_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import BadRequestError\n",
    "\n",
    "max_retries = 10\n",
    "retries = 0\n",
    "initial_delay = 5\n",
    "delay = initial_delay\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        batch_response = client.batches.create(\n",
    "            input_file_id=file_id,\n",
    "            endpoint=\"/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "        )\n",
    "        \n",
    "        # Save batch ID for later use\n",
    "        batch_id = batch_response.id\n",
    "        \n",
    "        print(f\"✅ Batch created successfully after {retries} retries\")\n",
    "        print(batch_response.model_dump_json(indent=2))\n",
    "        break  \n",
    "        \n",
    "    except BadRequestError as e:\n",
    "        error_message = str(e)\n",
    "        \n",
    "        # Check if it's a token limit error\n",
    "        if 'token_limit_exceeded' in error_message:\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                print(f\"❌ Maximum retries ({max_retries}) reached. Giving up.\")\n",
    "                raise\n",
    "            \n",
    "            print(f\"⏳ Token limit exceeded. Waiting {delay} seconds before retry {retries}/{max_retries}...\")\n",
    "            time.sleep(delay)\n",
    "            \n",
    "            # Exponential backoff - increase delay for next attempt\n",
    "            delay *= 2\n",
    "        else:\n",
    "            # If it's a different error, raise it immediately\n",
    "            print(f\"❌ Encountered non-token limit error: {error_message}\")\n",
    "            raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmr_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
