{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import base64\n",
    "from mimetypes import guess_type\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from PIL import Image\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Add the tools directory to the path\n",
    "sys.path.append('/data/users/brandon/ob1-projects/InternVL/internvl_chat/tools')\n",
    "\n",
    "from reasoning_data_pipeline.utils.accuracy_reward import (check_answer, parse_answer)\n",
    "\n",
    "from reasoning_data_pipeline.utils.utils import localtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI Configuration\n",
    "endpoint = \"https://dalle-declare.openai.azure.com/\"\n",
    "deployment = \"gpt-4.1\"\n",
    "api_version = \"2025-01-01-preview\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=os.getenv(\"AZURE_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Function to encode a local image into data URL \n",
    "def local_image_to_data_url(image_path):\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAVENDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        sample_max_num=None,\n",
    "        sample_start_idx=0,\n",
    "    ):\n",
    "        with open(data) as file:\n",
    "            self.data = file.readlines()\n",
    "\n",
    "        if sample_max_num is not None and len(self.data) > sample_max_num:\n",
    "            print(f'Truncate data lines. {len(self.data)} => {sample_max_num}')\n",
    "            step = max(len(self.data) // sample_max_num, 1)\n",
    "            self.data = self.data[sample_start_idx::step][:sample_max_num]\n",
    "            print(f'Number of data lines after truncation: {len(self.data)=}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = json.loads(self.data[idx])\n",
    "        \n",
    "        # RAVEN dataset structure: id, combined_image_path, correct_answer, subset_split\n",
    "        image_path = item['combined_image_path']\n",
    "        correct_answer = item['correct_answer']\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        rollout_user_prompt = r\"\"\"You are an abstract reasoning puzzle expert. The puzzle you will receive is presented in a standard Raven’s Progressive Matrices format: a 3×3 matrix of related images, with the bottom-right cell (the ninth tile) missing. There are eight possible answer choices provided separately, and your task is to decide which of those eight images correctly completes the 3×3 matrix pattern.\n",
    "\n",
    "I will provide you with an image containing:\n",
    "- Problem Matrix: An accompanying image that shows the eight tiles and highlights where the ninth is missing.\n",
    "- Answer Set: The eight candidate images from which you must choose the best fit for the missing tile.\n",
    "\n",
    "Your task is to:\n",
    "- Review the problem matrix and the accompanying image in sequence, describing step-by-step what you see in the image in <perception> tags.\n",
    "- Reason step-by-step about the logical pattern or rule connecting the tiles in <reasoning> tags.\n",
    "- Deduce the correct tile from the eight provided options in <correct_answer> tags.\n",
    "\n",
    "It is crucial that your solution contains these sections in the exact format described below:\n",
    "\n",
    "```\n",
    "[Perception]\n",
    "<step_1>\n",
    "...(Step 1 of step-by-step perception)...\n",
    "</step_1>\n",
    "<step_2>\n",
    "...(Step 2 of step-by-step perception)...\n",
    "</step_2>\n",
    "...\n",
    "<step_n>\n",
    "...(Step n of step-by-step perception)...\n",
    "</step_n>\n",
    "\n",
    "[Reasoning]\n",
    "<step_1>\n",
    "...(Step 1 of step-by-step reasoning)...\n",
    "</step_1>\n",
    "<step_2>\n",
    "...(Step 2 of step-by-step reasoning)...\n",
    "</step_2>\n",
    "...\n",
    "<step_m>\n",
    "...(Step m of step-by-step reasoning)...\n",
    "</step_m>\n",
    "\n",
    "<correct_answer>\n",
    "...(Clearly state which of the 8 candidate images is the best candidate image as the missing tile to complete the matrix. If the candidates are numbered, lettered, or can be uniquely described, use that identifier.)...\n",
    "</correct_answer>\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "        return {\n",
    "            'rollout_user_prompt': rollout_user_prompt,\n",
    "            'image': image,\n",
    "            'image_path': image_path,\n",
    "            'item': item.copy(),\n",
    "            'correct_answer': correct_answer,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response_to_perception_and_reasoning_steps_and_correct_answer(text, max_perception_steps=None, max_reasoning_steps=None):\n",
    "    \"\"\"\n",
    "    Parse text that contains perception steps, reasoning steps, and a correct answer.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to parse\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with 'perception_steps', 'reasoning_steps', and 'llm_answer'\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the text doesn't contain all required sections\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Initialize the result dictionary\n",
    "    result = {\n",
    "        'perception_steps': [],\n",
    "        'reasoning_steps': [],\n",
    "        'llm_answer': None\n",
    "    }\n",
    "    \n",
    "    # Extract perception steps\n",
    "    perception_pattern = r'\\[Perception\\](.*?)(?=\\[Reasoning\\]|\\Z)'\n",
    "    perception_match = re.search(perception_pattern, text, re.DOTALL)\n",
    "    \n",
    "    if not perception_match:\n",
    "        raise ValueError(\"Could not find Perception section\")\n",
    "    \n",
    "    perception_text = perception_match.group(1).strip()\n",
    "    step_pattern = r'<step_(\\d+)>(.*?)</step_\\1>'\n",
    "    perception_steps = re.findall(step_pattern, perception_text, re.DOTALL)\n",
    "    \n",
    "    if not perception_steps:\n",
    "        raise ValueError(\"Could not find any perception steps\")\n",
    "    \n",
    "    # Sort by step number and extract content\n",
    "    perception_steps.sort(key=lambda x: int(x[0]))\n",
    "    result['perception_steps'] = [step[1].strip() for step in perception_steps]\n",
    "    \n",
    "    # Extract reasoning steps\n",
    "    reasoning_pattern = r'\\[Reasoning\\](.*?)(?=<correct_answer>|\\Z)'\n",
    "    reasoning_match = re.search(reasoning_pattern, text, re.DOTALL)\n",
    "    \n",
    "    if not reasoning_match:\n",
    "        raise ValueError(\"Could not find Reasoning section\")\n",
    "    \n",
    "    reasoning_text = reasoning_match.group(1).strip()\n",
    "    reasoning_steps = re.findall(step_pattern, reasoning_text, re.DOTALL)\n",
    "    \n",
    "    if not reasoning_steps:\n",
    "        raise ValueError(\"Could not find any reasoning steps\")\n",
    "    \n",
    "    # Sort by step number and extract content\n",
    "    reasoning_steps.sort(key=lambda x: int(x[0]))\n",
    "    result['reasoning_steps'] = [step[1].strip() for step in reasoning_steps]\n",
    "    \n",
    "    # Extract correct answer\n",
    "    answer_pattern = r'<correct_answer>(.*?)</correct_answer>'\n",
    "    answer_match = re.search(answer_pattern, text, re.DOTALL)\n",
    "    \n",
    "    if not answer_match:\n",
    "        raise ValueError(\"Could not find correct answer\")\n",
    "    \n",
    "    result['llm_answer'] = answer_match.group(1).strip()\n",
    "    \n",
    "    # Final validation to ensure we have all components\n",
    "    if not result['perception_steps'] or not result['reasoning_steps'] or not result['llm_answer']:\n",
    "        raise ValueError(\"Missing one or more required components\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'perception_steps': ['The grid in image6 shows several animals placed at specific grid locations, with the ant (from image1) starting at a house (from image2) in the lower left corner of the grid. There are arrows shown for an example path leading to the ladybird (from image3) near the upper right corner.', 'The animals on the grid are: butterfly (upper right), bee (upper left), ladybird (one cell left of butterfly), snail (center), worm (bottom center), frog (bottom right), caterpillar (lower right).', 'The possible answer options at the bottom (image7) are: (A) butterfly, (B) bee, (C) worm, (D) snail, (E) caterpillar.', \"The question asks: Starting at the ant's home (bottom left), follow the arrows: right 2, down 2, right 3, up 3, right 2, up 2. Which animal is reached?\"], 'reasoning_steps': [\"Determine the starting position of the ant: bottom left corner (let's call this (1,1) on a standard grid).\", \"Apply the steps:\\n- Right 2: (1,1) → (3,1)\\n- Down 2: (3,1) → (3,3)\\n- Right 3: (3,3) → (6,3)\\n- Up 3: (6,3) → (6,0) (assuming the grid's y increases downward)\\n- Right 2: (6,0) → (8,0)\\n- Up 2: (8,0) → (8,-2)\\nBut let's check the grid layout and confirm axes.\", \"Looking closely at the example path, the grid's origin (1,1) is bottom left. Increasing x is right, increasing y is up. So let's try:\\n- Start at (1,1).\\n- Right 2: (3,1)\\n- Down 2: (3,-1) (this would go off-grid; but in the example, down means up the page, so maybe y increases downward).\\n- Instead, let's look at the example. The given path for the ladybird (→3, ↑3, →3, ↑1) matches the drawn arrows.\\n- Let's count grid rows from bottom left as (1,1), moving right (x) and up (y).\", \"Based on the image's arrows, the bottom left is (1,1), rightward is x+, upward is y+. We'll follow the instructions:\\n- Start: (1,1)\\n- →2: (3,1)\\n- ↓2: (3,3)\\n- →3: (6,3)\\n- ↑3: (6,6)\\n- →2: (8,6)\\n- ↑2: (8,8)\\nNow check which animal is at (8,8).\", 'Counting the columns and rows in the grid, the top right cell (where the butterfly is) is (8,8).'], 'llm_answer': 'The animal reached is the butterfly, which matches option (A).\\nCorrect option: A'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'perception_steps': ['The image shows a grid with several animals and a house. The ant starts at the house in the bottom left corner. There are arrows showing possible moves, and animals are placed at various squares.', 'The animals in the grid are (from left to right, top to bottom): a bee, a ladybird, a butterfly, a snail, a green worm, and a frog.', 'The available moves from the house are shown as arrows, but the question asks us to move according to a new sequence: $\\\\rightarrow 2, \\\\downarrow 2, \\\\rightarrow 3, \\\\uparrow 3, \\\\rightarrow 2, \\\\uparrow 2$.', 'The answer choices are: (A) butterfly, (B) bee, (C) green worm, (D) snail, (E) frog.'], 'reasoning_steps': [\"Let's start at the house, which is at the bottom left corner of the grid.\", 'Move $\\\\rightarrow 2$: Move 2 squares right. Now at the third column from the left, still bottom row.', 'Move $\\\\downarrow 2$: Move 2 squares down. But since we are already at the bottom row, this must mean the grid\\'s origin is at the top left, and \"down\" means move up the grid. So, from the bottom row, moving \"down\" 2 squares keeps us at the same row (or perhaps this is a typo and should be \"up\"). Let\\'s check the previous path for reference.', 'Reviewing the sample path: $\\\\rightarrow 3, \\\\uparrow 3, \\\\rightarrow 3, \\\\uparrow 1$ gets to the ladybird. Starting from home (bottom left): right 3 (column 4, bottom), up 3 (column 4, row 3 from bottom), right 3 (column 7, row 3 from bottom), up 1 (column 7, row 4 from bottom) — this matches the ladybird\\'s position. So, \"up\" means moving toward the top of the grid, \"down\" means toward the bottom.', 'Apply moves:\\n- Start at (1,1) (bottom-left is (1,1)).\\n- $\\\\rightarrow 2$: (3,1)\\n- $\\\\downarrow 2$: (3,-1) (but can\\'t go lower than row 1, so this must mean something else—perhaps \"down\" is up the grid).\\n- Let\\'s invert: (3,1) + $\\\\downarrow 2$ = (3,3) (move up 2 rows).\\n- $\\\\rightarrow 3$: (6,3)\\n- $\\\\uparrow 3$: (6,0) (can\\'t go above row 1, so must be moving down the grid).\\n- From sample, \"up\" increases row number (moves up the grid). Let\\'s assign bottom row as row 1, increasing upward.\\n- So, (6,3) + $\\\\uparrow 3$ = (6,6)\\n- $\\\\rightarrow 2$: (8,6)\\n- $\\\\uparrow 2$: (8,8)\\n- But the grid is 7 columns by 7 rows. Let\\'s count grid dimensions.', \"The grid is 7 columns (left to right), 7 rows (bottom to top). Let's number columns 1-7 (left to right), rows 1-7 (bottom to top).\\n- Start: (1,1)\\n- $\\\\rightarrow 2$: (3,1)\\n- $\\\\downarrow 2$: (3,3)\\n- $\\\\rightarrow 3$: (6,3)\\n- $\\\\uparrow 3$: (6,6)\\n- $\\\\rightarrow 2$: (7,6) (cannot move beyond 7 columns)\\n- $\\\\uparrow 2$: (7,7) (cannot move beyond 7 rows)\\nNow, let's match (7,7) to the animal on the grid.\", 'The animal at the top right corner (7,7) is the butterfly.'], 'llm_answer': '(A) Butterfly'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "good_example_1 = \"[Perception]\\n<step_1>\\nThe grid in image6 shows several animals placed at specific grid locations, with the ant (from image1) starting at a house (from image2) in the lower left corner of the grid. There are arrows shown for an example path leading to the ladybird (from image3) near the upper right corner.\\n</step_1>\\n<step_2>\\nThe animals on the grid are: butterfly (upper right), bee (upper left), ladybird (one cell left of butterfly), snail (center), worm (bottom center), frog (bottom right), caterpillar (lower right).\\n</step_2>\\n<step_3>\\nThe possible answer options at the bottom (image7) are: (A) butterfly, (B) bee, (C) worm, (D) snail, (E) caterpillar.\\n</step_3>\\n<step_4>\\nThe question asks: Starting at the ant's home (bottom left), follow the arrows: right 2, down 2, right 3, up 3, right 2, up 2. Which animal is reached?\\n</step_4>\\n\\n[Reasoning]\\n<step_1>\\nDetermine the starting position of the ant: bottom left corner (let's call this (1,1) on a standard grid).\\n</step_1>\\n<step_2>\\nApply the steps:\\n- Right 2: (1,1) → (3,1)\\n- Down 2: (3,1) → (3,3)\\n- Right 3: (3,3) → (6,3)\\n- Up 3: (6,3) → (6,0) (assuming the grid's y increases downward)\\n- Right 2: (6,0) → (8,0)\\n- Up 2: (8,0) → (8,-2)\\nBut let's check the grid layout and confirm axes.\\n</step_2>\\n<step_3>\\nLooking closely at the example path, the grid's origin (1,1) is bottom left. Increasing x is right, increasing y is up. So let's try:\\n- Start at (1,1).\\n- Right 2: (3,1)\\n- Down 2: (3,-1) (this would go off-grid; but in the example, down means up the page, so maybe y increases downward).\\n- Instead, let's look at the example. The given path for the ladybird (→3, ↑3, →3, ↑1) matches the drawn arrows.\\n- Let's count grid rows from bottom left as (1,1), moving right (x) and up (y).\\n</step_3>\\n<step_4>\\nBased on the image's arrows, the bottom left is (1,1), rightward is x+, upward is y+. We'll follow the instructions:\\n- Start: (1,1)\\n- →2: (3,1)\\n- ↓2: (3,3)\\n- →3: (6,3)\\n- ↑3: (6,6)\\n- →2: (8,6)\\n- ↑2: (8,8)\\nNow check which animal is at (8,8).\\n</step_4>\\n<step_5>\\nCounting the columns and rows in the grid, the top right cell (where the butterfly is) is (8,8).\\n</step_5>\\n\\n<correct_answer>\\nThe animal reached is the butterfly, which matches option (A).\\nCorrect option: A\\n</correct_answer>\"\n",
    "\n",
    "ge_2 = \"[Perception]\\n<step_1>\\nThe image shows a grid with several animals and a house. The ant starts at the house in the bottom left corner. There are arrows showing possible moves, and animals are placed at various squares.\\n</step_1>\\n<step_2>\\nThe animals in the grid are (from left to right, top to bottom): a bee, a ladybird, a butterfly, a snail, a green worm, and a frog.\\n</step_2>\\n<step_3>\\nThe available moves from the house are shown as arrows, but the question asks us to move according to a new sequence: $\\\\rightarrow 2, \\\\downarrow 2, \\\\rightarrow 3, \\\\uparrow 3, \\\\rightarrow 2, \\\\uparrow 2$.\\n</step_3>\\n<step_4>\\nThe answer choices are: (A) butterfly, (B) bee, (C) green worm, (D) snail, (E) frog.\\n</step_4>\\n\\n[Reasoning]\\n<step_1>\\nLet's start at the house, which is at the bottom left corner of the grid.\\n</step_1>\\n<step_2>\\nMove $\\\\rightarrow 2$: Move 2 squares right. Now at the third column from the left, still bottom row.\\n</step_2>\\n<step_3>\\nMove $\\\\downarrow 2$: Move 2 squares down. But since we are already at the bottom row, this must mean the grid's origin is at the top left, and \\\"down\\\" means move up the grid. So, from the bottom row, moving \\\"down\\\" 2 squares keeps us at the same row (or perhaps this is a typo and should be \\\"up\\\"). Let's check the previous path for reference.\\n</step_3>\\n<step_4>\\nReviewing the sample path: $\\\\rightarrow 3, \\\\uparrow 3, \\\\rightarrow 3, \\\\uparrow 1$ gets to the ladybird. Starting from home (bottom left): right 3 (column 4, bottom), up 3 (column 4, row 3 from bottom), right 3 (column 7, row 3 from bottom), up 1 (column 7, row 4 from bottom) — this matches the ladybird's position. So, \\\"up\\\" means moving toward the top of the grid, \\\"down\\\" means toward the bottom.\\n</step_4>\\n<step_5>\\nApply moves:\\n- Start at (1,1) (bottom-left is (1,1)).\\n- $\\\\rightarrow 2$: (3,1)\\n- $\\\\downarrow 2$: (3,-1) (but can't go lower than row 1, so this must mean something else—perhaps \\\"down\\\" is up the grid).\\n- Let's invert: (3,1) + $\\\\downarrow 2$ = (3,3) (move up 2 rows).\\n- $\\\\rightarrow 3$: (6,3)\\n- $\\\\uparrow 3$: (6,0) (can't go above row 1, so must be moving down the grid).\\n- From sample, \\\"up\\\" increases row number (moves up the grid). Let's assign bottom row as row 1, increasing upward.\\n- So, (6,3) + $\\\\uparrow 3$ = (6,6)\\n- $\\\\rightarrow 2$: (8,6)\\n- $\\\\uparrow 2$: (8,8)\\n- But the grid is 7 columns by 7 rows. Let's count grid dimensions.\\n</step_5>\\n<step_6>\\nThe grid is 7 columns (left to right), 7 rows (bottom to top). Let's number columns 1-7 (left to right), rows 1-7 (bottom to top).\\n- Start: (1,1)\\n- $\\\\rightarrow 2$: (3,1)\\n- $\\\\downarrow 2$: (3,3)\\n- $\\\\rightarrow 3$: (6,3)\\n- $\\\\uparrow 3$: (6,6)\\n- $\\\\rightarrow 2$: (7,6) (cannot move beyond 7 columns)\\n- $\\\\uparrow 2$: (7,7) (cannot move beyond 7 rows)\\nNow, let's match (7,7) to the animal on the grid.\\n</step_6>\\n<step_7>\\nThe animal at the top right corner (7,7) is the butterfly.\\n</step_7>\\n\\n<correct_answer>\\n(A) Butterfly\\n</correct_answer>\"\n",
    "\n",
    "for example in [good_example_1, ge_2]:\n",
    "    steps = parse_response_to_perception_and_reasoning_steps_and_correct_answer(example)\n",
    "    print(steps)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_responses_azure(inputs, num_return_sequences=1, prefixes=None, max_new_tokens=4096, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Build responses using Azure OpenAI GPT-4.1\n",
    "    inputs: list of (prompt, image) tuples\n",
    "    \"\"\"\n",
    "    batched_response_list = [[] for _ in range(len(inputs))]\n",
    "    \n",
    "    for seq_idx in range(num_return_sequences):\n",
    "        for input_idx, (prompt, image) in enumerate(inputs):\n",
    "            try:\n",
    "                # Convert image to data URL\n",
    "                if isinstance(image, str):\n",
    "                    # If image is a path\n",
    "                    data_url = local_image_to_data_url(image)\n",
    "                else:\n",
    "                    # If image is PIL Image, save temporarily and convert\n",
    "                    temp_path = f\"/tmp/temp_image_{input_idx}_{seq_idx}.png\"\n",
    "                    image.save(temp_path)\n",
    "                    data_url = local_image_to_data_url(temp_path)\n",
    "                    os.remove(temp_path)\n",
    "                \n",
    "                # Prepare messages - no need to remove IMG_PLACEHOLDER since it's already cleaned\n",
    "                content = [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}}\n",
    "                ]\n",
    "                \n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that excels at visual reasoning and pattern recognition.\"},\n",
    "                    {\"role\": \"user\", \"content\": content}\n",
    "                ]\n",
    "                \n",
    "                # Add prefix if provided\n",
    "                if prefixes is not None:\n",
    "                    messages.append({\n",
    "                        \"role\": \"assistant\", \n",
    "                        \"content\": prefixes[input_idx]\n",
    "                    })\n",
    "                \n",
    "                # Call Azure OpenAI\n",
    "                response = client.chat.completions.create(\n",
    "                    messages=messages,\n",
    "                    max_completion_tokens=max_new_tokens,\n",
    "                    model=deployment,\n",
    "                    temperature=temperature\n",
    "                )\n",
    "                \n",
    "                response_text = response.choices[0].message.content\n",
    "                \n",
    "                # Add prefix if provided\n",
    "                if prefixes is not None:\n",
    "                    response_text = f'{prefixes[input_idx]}{response_text}'\n",
    "                \n",
    "                batched_response_list[input_idx].append(response_text)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error generating response for input {input_idx}, sequence {seq_idx}: {e}\")\n",
    "                batched_response_list[input_idx].append(\"\")\n",
    "    \n",
    "    return sum(batched_response_list, start=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_steps(steps, sep='\\n\\n'):\n",
    "    return sep.join(steps)\n",
    "\n",
    "def build_mc_scores(inputs, response_list, items, num_return_sequences, args):\n",
    "    \"\"\"\n",
    "    Build Monte Carlo scores for each step in the responses\n",
    "    \"\"\"\n",
    "    assert len(response_list) == len(inputs) * num_return_sequences\n",
    "\n",
    "    steps_list = [parse_response_to_perception_and_reasoning_steps_and_correct_answer(response, max_perception_steps=args.get('max_perception_steps', 12), max_reasoning_steps=args.get('max_reasoning_steps', 12)) for response in response_list] # TODO: merge after max steps are reached. \n",
    "    \n",
    "    # Convert structured steps to flat lists for processing\n",
    "    flat_steps_list = []\n",
    "    for steps_dict in steps_list:\n",
    "        # Combine perception and reasoning steps into a single flat list\n",
    "        flat_steps = steps_dict['perception_steps'] + steps_dict['reasoning_steps']\n",
    "        flat_steps_list.append(flat_steps)\n",
    "    \n",
    "    steps_flag = [False for _ in range(len(response_list))]\n",
    "    steps_outputs = [[] for _ in range(len(response_list))]\n",
    "\n",
    "    step_cnt = 0\n",
    "    while True:\n",
    "        curr_inputs_idx = []\n",
    "        curr_inputs = []\n",
    "        curr_prefixes = []\n",
    "        curr_answer_gt = []\n",
    "        \n",
    "        for idx, (flat_steps, flag) in enumerate(zip(flat_steps_list, steps_flag)):\n",
    "            if step_cnt >= len(flat_steps):\n",
    "                continue\n",
    "\n",
    "            if flag:\n",
    "                steps_outputs[idx].append({\n",
    "                    'step': flat_steps[step_cnt],\n",
    "                    'score': 0.0,\n",
    "                    'num_mc_correct': 0,\n",
    "                    'num_mc_total': 0,\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            input = inputs[idx // num_return_sequences]\n",
    "            item = items[idx // num_return_sequences]\n",
    "\n",
    "            curr_inputs_idx.append(idx)\n",
    "            curr_inputs.append(input)\n",
    "            \n",
    "            # Build prefix: perception + reasoning up to current step\n",
    "            prefix_steps = flat_steps[:step_cnt+1]\n",
    "            \n",
    "            # Reconstruct the proper format for the prefix\n",
    "            perception_count = len(steps_list[idx]['perception_steps'])\n",
    "            if step_cnt < perception_count:\n",
    "                # We're still in perception steps\n",
    "                perception_prefix = prefix_steps\n",
    "                reasoning_prefix = []\n",
    "            else:\n",
    "                # We're in reasoning steps\n",
    "                perception_prefix = steps_list[idx]['perception_steps']\n",
    "                reasoning_prefix = prefix_steps[perception_count:]\n",
    "            \n",
    "            # Format the prefix properly\n",
    "            formatted_prefix = \"\"\n",
    "            if perception_prefix:\n",
    "                formatted_prefix += \"[Perception]\\n\"\n",
    "                for i, step in enumerate(perception_prefix):\n",
    "                    formatted_prefix += f\"<step_{i+1}>\\n{step}\\n</step_{i+1}>\\n\"\n",
    "                formatted_prefix += \"\\n\"\n",
    "            \n",
    "            if reasoning_prefix:\n",
    "                formatted_prefix += \"[Reasoning]\\n\"\n",
    "                for i, step in enumerate(reasoning_prefix):\n",
    "                    formatted_prefix += f\"<step_{i+1}>\\n{step}\\n</step_{i+1}>\\n\"\n",
    "            \n",
    "            curr_prefixes.append(formatted_prefix.strip())\n",
    "            curr_answer_gt.append(item['correct_answer'])\n",
    "\n",
    "            # # Get the original problem prompt for this item\n",
    "            # original_input = inputs[idx // num_return_sequences]  # Get the original input\n",
    "            # item_data = items[idx // num_return_sequences]       # Get the item data\n",
    "\n",
    "            # # Build complete prompt with original context + current steps\n",
    "            # if hasattr(item_data, 'rollout_user_prompt'):\n",
    "            #     rollout_prompt = item_data.rollout_user_prompt\n",
    "            # elif 'rollout_user_prompt' in item_data:\n",
    "            #     rollout_prompt = item_data['rollout_user_prompt']\n",
    "            # else:\n",
    "            #     # Fallback: construct from item data\n",
    "            #     rollout_prompt = f\"Question: {item_data.get('question', '')}\\nChoose the correct answer from the options.\"\n",
    "\n",
    "            # # Replace the last entry in curr_prefixes with full context\n",
    "            # full_context = f\"{rollout_prompt}\\n\\n{formatted_prefix.strip()}\"\n",
    "            # curr_prefixes[-1] = full_context\n",
    "\n",
    "\n",
    "            print(\"idx\", idx)\n",
    "            print(\"STEPS ONLY:\", formatted_prefix.strip())\n",
    "            print(\"ORIGINAL ITEM:\", items[idx // num_return_sequences])\n",
    "            print(\"curr_answer_gt:\", curr_answer_gt)\n",
    "\n",
    "        # if len(curr_inputs) <= 0:\n",
    "        #     for idx, flat_steps in enumerate(flat_steps_list):\n",
    "        #         for step_idx in range(len(flat_steps) - step_cnt - 1):\n",
    "        #             steps_outputs[idx].append({\n",
    "        #                 'step': flat_steps[step_cnt + step_idx + 1],\n",
    "        #                 'score': 0.0,\n",
    "        #                 'num_mc_correct': 0,\n",
    "        #                 'num_mc_total': 0,\n",
    "        #             })\n",
    "        #     break\n",
    "\n",
    "        # Here is where based on the current steps (prefixes), we rollout to get mc soft estimation. \n",
    "        # mc_response_list = build_responses_azure(\n",
    "        #     curr_inputs, \n",
    "        #     args.get('num_mc_sequences', 16), \n",
    "        #     curr_prefixes,\n",
    "        #     max_new_tokens=args.get('max_new_tokens', 4096),\n",
    "        #     temperature=args.get('temperature', 1.0)\n",
    "        # )\n",
    "\n",
    "\n",
    "        # Here is where we get the correctness of the rollouts to label the corresponding rollout as correct or incorrect. \n",
    "        # correctness_list = []\n",
    "        # for mc_idx, mc_response in enumerate(mc_response_list):\n",
    "        #     try:\n",
    "        #         # For RAVEN, we need to extract the final answer (number 1-8)\n",
    "        #         correctness = check_answer(\n",
    "        #             answer_pred=parse_answer(mc_response, prompt_version=args.get('prompt_version', 'en_v2'))[-1], # parse based on answer format\n",
    "        #             answer_gt=curr_answer_gt[mc_idx // args.get('num_mc_sequences', 16)],\n",
    "        #             mode='raven'  # Use RAVEN verification mode\n",
    "        #         )\n",
    "        #     except Exception as e:\n",
    "        #         print(f'Fail to check correctness for response: {mc_response[:100]}... Error: {e}')\n",
    "        #         correctness = 0\n",
    "        #     correctness_list.append(correctness)\n",
    "\n",
    "        # assert len(mc_response_list) == len(correctness_list)\n",
    "        # assert len(mc_response_list) == len(curr_inputs) * args.get('num_mc_sequences', 16)\n",
    "\n",
    "        # for idx_idx, idx in enumerate(curr_inputs_idx):\n",
    "        #     curr_correctness_list = correctness_list[idx_idx*args.get('num_mc_sequences', 16):(idx_idx+1)*args.get('num_mc_sequences', 16)]\n",
    "        #     score = sum(curr_correctness_list) / len(curr_correctness_list)\n",
    "        #     steps_outputs[idx].append({\n",
    "        #         'step': flat_steps_list[idx][step_cnt],\n",
    "        #         'score': score,\n",
    "        #         'num_mc_correct': sum(curr_correctness_list),\n",
    "        #         'num_mc_total': len(curr_correctness_list),\n",
    "        #     })\n",
    "\n",
    "        #     if score == 0 and args.get('early_stop', True):\n",
    "        #         steps_flag[idx] = True\n",
    "\n",
    "        step_cnt += 1\n",
    "    return\n",
    "    return steps_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_process_supervision(inputs, items, num_return_sequences, args):\n",
    "    \"\"\"\n",
    "    Build process supervision data with step-by-step scoring\n",
    "    \"\"\"\n",
    "    response_list = build_responses_azure(\n",
    "        inputs, \n",
    "        num_return_sequences,\n",
    "        max_new_tokens=args.get('max_new_tokens', 4096),\n",
    "        temperature=args.get('temperature', 1.0)\n",
    "    )\n",
    "\n",
    "    print(\"responses produced by build_process_supervision\", response_list) # num_return_sequences = n, so n rollouts for each input image. \n",
    "    steps_with_score = build_mc_scores(inputs, response_list, items, num_return_sequences, args)\n",
    "    return\n",
    "\n",
    "    # outputs = []\n",
    "\n",
    "    # for idx, (response, each_steps_with_score) in enumerate(zip(response_list, steps_with_score)):\n",
    "    #     input = inputs[idx // num_return_sequences]\n",
    "    #     item = items[idx // num_return_sequences]\n",
    "\n",
    "    #     output = item.copy()\n",
    "    #     output['response'] = response\n",
    "    #     output['steps_with_score'] = each_steps_with_score\n",
    "    #     output['question'] = input[0]  # Store the formatted question\n",
    "    #     outputs.append(output)\n",
    "\n",
    "    # return outputs\n",
    "\n",
    "\n",
    "# def print_process_supervision(output):\n",
    "#     \"\"\"\n",
    "#     Print process supervision output for debugging\n",
    "#     \"\"\"\n",
    "#     steps_with_score = output['steps_with_score']\n",
    "#     print('[Response] Start')\n",
    "#     for step_idx, step in enumerate(steps_with_score):\n",
    "#         print(\n",
    "#             f'[Steps-{step_idx}] Start\\n'\n",
    "#             f\"{step['step']}\\n\\n\"\n",
    "#             f\"Score: {step['score']}\\n\"\n",
    "#             f\"MC Correct: {step['num_mc_correct']}\\n\"\n",
    "#             f\"MC Total: {step['num_mc_total']}\\n\"\n",
    "#             f'[Steps-{step_idx}] End\\n'\n",
    "#         )\n",
    "#     print('[Response] End')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'prompt_path': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/raven_processed_jsonl/center_single_train.jsonl', 'out_dir': 'raven_rollouts_output', 'batch_size': 1, 'num_return_sequences': 1, 'sample_start_idx': 0, 'sample_max_num': 50, 'prompt_version': 'en_v2', 'num_mc_sequences': 4, 'max_perception_steps': 12, 'max_reasoning_steps': 12, 'early_stop': True, 'max_new_tokens': 4096, 'temperature': 1.0}\n",
      "Using Azure OpenAI endpoint: https://dalle-declare.openai.azure.com/\n",
      "Model deployment: gpt-4.1\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters\n",
    "args = {\n",
    "    'prompt_path': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/raven_processed_jsonl/center_single_train.jsonl',\n",
    "    'out_dir': 'raven_rollouts_output',\n",
    "    'batch_size': 1,\n",
    "    'num_return_sequences': 1,\n",
    "    'sample_start_idx': 0,\n",
    "    'sample_max_num': 50,  # Limit for testing\n",
    "    'prompt_version': 'en_v2',\n",
    "    'num_mc_sequences': 4,  # Reduced for faster testing\n",
    "    'max_perception_steps': 12,\n",
    "    'max_reasoning_steps': 12,\n",
    "    'early_stop': True,\n",
    "    'max_new_tokens': 4096,\n",
    "    'temperature': 1.0,\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(args['out_dir'], exist_ok=True)\n",
    "\n",
    "print(f\"Configuration: {args}\")\n",
    "print(f\"Using Azure OpenAI endpoint: {endpoint}\")\n",
    "print(f\"Model deployment: {deployment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncate data lines. 6000 => 50\n",
      "Number of data lines after truncation: len(self.data)=50\n",
      "Dataset loaded: 50 samples\n",
      "\n",
      "[2025-06-05 20:14:32] Processing sample 1/1\n",
      "Image path: /data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images/center_single/train/3023.png\n",
      "Correct answer: 5\n",
      "responses produced by build_process_supervision ['[Perception]\\n<step_1>\\nThe problem matrix is a 3×3 grid with the bottom right cell missing (the 9th cell labeled as \"?\").\\n</step_1>\\n<step_2>\\nFirst row (left to right): black circle, light gray circle, black circle.\\n</step_2>\\n<step_3>\\nSecond row (left to right): black pentagon, outlined pentagon, black hexagon.\\n</step_3>\\n<step_4>\\nThird row (left to right): dark gray circle, light gray circle, missing tile.\\n</step_4>\\n<step_5>\\nThe answer set displays 8 candidate tiles:\\n1. Black circle.\\n2. Light gray circle.\\n3. Black triangle.\\n4. Light gray outlined circle.\\n5. Dark gray circle.\\n6. Medium gray circle.\\n7. Black pentagon.\\n8. Black hexagon.\\n</step_5>\\n\\n[Reasoning]\\n<step_1>\\nLooking at the matrix by shape: all cells in each row have the same shape (Row 1 = circle, Row 2 = pentagon, Row 3 = circle).\\n</step_1>\\n<step_2>\\nWithin each row, the color scheme alternates or follows a logic:\\n- Row 1: black circle, light gray outlined circle, black circle (dark-dark-light).\\n- Row 2: black pentagon, outlined pentagon, black hexagon (dark-outline-dark, with a shape change at rightmost position).\\n- Row 3: dark gray circle, light gray circle, (missing tile).\\n</step_2>\\n<step_3>\\nExamining the columns:\\n- First column: black circle, black pentagon, dark gray circle.\\n- Second column: light gray outlined circle, outlined pentagon, light gray circle.\\n- Third column: black circle, black hexagon, (missing tile).\\n</step_3>\\n<step_4>\\nThe missing tile needs to be a circle (to match the row’s shapes).\\n</step_4>\\n<step_5>\\nThe color pattern for circles in the third column (top to bottom) is: black (circle), black (hexagon), ?. The first in the row (third row) is dark gray circle, second is light gray circle. This suggests a shade progression from dark gray to light gray, so the third circle could be black, to fit the darkest-lightest-darkest circular progression, consistent with other rows and maintain the sequence.\\n</step_5>\\n<step_6>\\nOnly answer choices 1 and 5 show a circle—1 is black, 5 is dark gray. But 5 matches the first cell of the row, which would break the row’s progression (shouldn’t repeat the same color). Answer 1 fits better, as it provides distinct values across the row and column, and maintains pattern symmetry.\\n</step_6>\\n\\n<correct_answer>\\n1 (Black circle)\\n</correct_answer>']\n",
      "idx 0\n",
      "STEPS ONLY: [Perception]\n",
      "<step_1>\n",
      "The problem matrix is a 3×3 grid with the bottom right cell missing (the 9th cell labeled as \"?\").\n",
      "</step_1>\n",
      "ORIGINAL ITEM: {'id': 3023, 'combined_image_path': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images/center_single/train/3023.png', 'correct_answer': 5, 'subset_split': 'center_single_train'}\n",
      "curr_answer_gt: [5]\n",
      "idx 0\n",
      "STEPS ONLY: [Perception]\n",
      "<step_1>\n",
      "The problem matrix is a 3×3 grid with the bottom right cell missing (the 9th cell labeled as \"?\").\n",
      "</step_1>\n",
      "<step_2>\n",
      "First row (left to right): black circle, light gray circle, black circle.\n",
      "</step_2>\n",
      "ORIGINAL ITEM: {'id': 3023, 'combined_image_path': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images/center_single/train/3023.png', 'correct_answer': 5, 'subset_split': 'center_single_train'}\n",
      "curr_answer_gt: [5]\n",
      "idx 0\n",
      "STEPS ONLY: [Perception]\n",
      "<step_1>\n",
      "The problem matrix is a 3×3 grid with the bottom right cell missing (the 9th cell labeled as \"?\").\n",
      "</step_1>\n",
      "<step_2>\n",
      "First row (left to right): black circle, light gray circle, black circle.\n",
      "</step_2>\n",
      "<step_3>\n",
      "Second row (left to right): black pentagon, outlined pentagon, black hexagon.\n",
      "</step_3>\n",
      "ORIGINAL ITEM: {'id': 3023, 'combined_image_path': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images/center_single/train/3023.png', 'correct_answer': 5, 'subset_split': 'center_single_train'}\n",
      "curr_answer_gt: [5]\n",
      "idx 0\n",
      "STEPS ONLY: [Perception]\n",
      "<step_1>\n",
      "The problem matrix is a 3×3 grid with the bottom right cell missing (the 9th cell labeled as \"?\").\n",
      "</step_1>\n",
      "<step_2>\n",
      "First row (left to right): black circle, light gray circle, black circle.\n",
      "</step_2>\n",
      "<step_3>\n",
      "Second row (left to right): black pentagon, outlined pentagon, black hexagon.\n",
      "</step_3>\n",
      "<step_4>\n",
      "Third row (left to right): dark gray circle, light gray circle, missing tile.\n",
      "</step_4>\n",
      "ORIGINAL ITEM: {'id': 3023, 'combined_image_path': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images/center_single/train/3023.png', 'correct_answer': 5, 'subset_split': 'center_single_train'}\n",
      "curr_answer_gt: [5]\n",
      "idx 0\n",
      "STEPS ONLY: [Perception]\n",
      "<step_1>\n",
      "The problem matrix is a 3×3 grid with the bottom right cell missing (the 9th cell labeled as \"?\").\n",
      "</step_1>\n",
      "<step_2>\n",
      "First row (left to right): black circle, light gray circle, black circle.\n",
      "</step_2>\n",
      "<step_3>\n",
      "Second row (left to right): black pentagon, outlined pentagon, black hexagon.\n",
      "</step_3>\n",
      "<step_4>\n",
      "Third row (left to right): dark gray circle, light gray circle, missing tile.\n",
      "</step_4>\n",
      "<step_5>\n",
      "The answer set displays 8 candidate tiles:\n",
      "1. Black circle.\n",
      "2. Light gray circle.\n",
      "3. Black triangle.\n",
      "4. Light gray outlined circle.\n",
      "5. Dark gray circle.\n",
      "6. Medium gray circle.\n",
      "7. Black pentagon.\n",
      "8. Black hexagon.\n",
      "</step_5>\n",
      "ORIGINAL ITEM: {'id': 3023, 'combined_image_path': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images/center_single/train/3023.png', 'correct_answer': 5, 'subset_split': 'center_single_train'}\n",
      "curr_answer_gt: [5]\n",
      "idx 0\n",
      "STEPS ONLY: [Perception]\n",
      "<step_1>\n",
      "The problem matrix is a 3×3 grid with the bottom right cell missing (the 9th cell labeled as \"?\").\n",
      "</step_1>\n",
      "<step_2>\n",
      "First row (left to right): black circle, light gray circle, black circle.\n",
      "</step_2>\n",
      "<step_3>\n",
      "Second row (left to right): black pentagon, outlined pentagon, black hexagon.\n",
      "</step_3>\n",
      "<step_4>\n",
      "Third row (left to right): dark gray circle, light gray circle, missing tile.\n",
      "</step_4>\n",
      "<step_5>\n",
      "The answer set displays 8 candidate tiles:\n",
      "1. Black circle.\n",
      "2. Light gray circle.\n",
      "3. Black triangle.\n",
      "4. Light gray outlined circle.\n",
      "5. Dark gray circle.\n",
      "6. Medium gray circle.\n",
      "7. Black pentagon.\n",
      "8. Black hexagon.\n",
      "</step_5>\n",
      "\n",
      "[Reasoning]\n",
      "<step_1>\n",
      "Looking at the matrix by shape: all cells in each row have the same shape (Row 1 = circle, Row 2 = pentagon, Row 3 = circle).\n",
      "</step_1>\n",
      "ORIGINAL ITEM: {'id': 3023, 'combined_image_path': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images/center_single/train/3023.png', 'correct_answer': 5, 'subset_split': 'center_single_train'}\n",
      "curr_answer_gt: [5]\n",
      "idx 0\n",
      "STEPS ONLY: [Perception]\n",
      "<step_1>\n",
      "The problem matrix is a 3×3 grid with the bottom right cell missing (the 9th cell labeled as \"?\").\n",
      "</step_1>\n",
      "<step_2>\n",
      "First row (left to right): black circle, light gray circle, black circle.\n",
      "</step_2>\n",
      "<step_3>\n",
      "Second row (left to right): black pentagon, outlined pentagon, black hexagon.\n",
      "</step_3>\n",
      "<step_4>\n",
      "Third row (left to right): dark gray circle, light gray circle, missing tile.\n",
      "</step_4>\n",
      "<step_5>\n",
      "The answer set displays 8 candidate tiles:\n",
      "1. Black circle.\n",
      "2. Light gray circle.\n",
      "3. Black triangle.\n",
      "4. Light gray outlined circle.\n",
      "5. Dark gray circle.\n",
      "6. Medium gray circle.\n",
      "7. Black pentagon.\n",
      "8. Black hexagon.\n",
      "</step_5>\n",
      "\n",
      "[Reasoning]\n",
      "<step_1>\n",
      "Looking at the matrix by shape: all cells in each row have the same shape (Row 1 = circle, Row 2 = pentagon, Row 3 = circle).\n",
      "</step_1>\n",
      "<step_2>\n",
      "Within each row, the color scheme alternates or follows a logic:\n",
      "- Row 1: black circle, light gray outlined circle, black circle (dark-dark-light).\n",
      "- Row 2: black pentagon, outlined pentagon, black hexagon (dark-outline-dark, with a shape change at rightmost position).\n",
      "- Row 3: dark gray circle, light gray circle, (missing tile).\n",
      "</step_2>\n",
      "ORIGINAL ITEM: {'id': 3023, 'combined_image_path': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images/center_single/train/3023.png', 'correct_answer': 5, 'subset_split': 'center_single_train'}\n",
      "curr_answer_gt: [5]\n",
      "idx 0\n",
      "STEPS ONLY: [Perception]\n",
      "<step_1>\n",
      "The problem matrix is a 3×3 grid with the bottom right cell missing (the 9th cell labeled as \"?\").\n",
      "</step_1>\n",
      "<step_2>\n",
      "First row (left to right): black circle, light gray circle, black circle.\n",
      "</step_2>\n",
      "<step_3>\n",
      "Second row (left to right): black pentagon, outlined pentagon, black hexagon.\n",
      "</step_3>\n",
      "<step_4>\n",
      "Third row (left to right): dark gray circle, light gray circle, missing tile.\n",
      "</step_4>\n",
      "<step_5>\n",
      "The answer set displays 8 candidate tiles:\n",
      "1. Black circle.\n",
      "2. Light gray circle.\n",
      "3. Black triangle.\n",
      "4. Light gray outlined circle.\n",
      "5. Dark gray circle.\n",
      "6. Medium gray circle.\n",
      "7. Black pentagon.\n",
      "8. Black hexagon.\n",
      "</step_5>\n",
      "\n",
      "[Reasoning]\n",
      "<step_1>\n",
      "Looking at the matrix by shape: all cells in each row have the same shape (Row 1 = circle, Row 2 = pentagon, Row 3 = circle).\n",
      "</step_1>\n",
      "<step_2>\n",
      "Within each row, the color scheme alternates or follows a logic:\n",
      "- Row 1: black circle, light gray outlined circle, black circle (dark-dark-light).\n",
      "- Row 2: black pentagon, outlined pentagon, black hexagon (dark-outline-dark, with a shape change at rightmost position).\n",
      "- Row 3: dark gray circle, light gray circle, (missing tile).\n",
      "</step_2>\n",
      "<step_3>\n",
      "Examining the columns:\n",
      "- First column: black circle, black pentagon, dark gray circle.\n",
      "- Second column: light gray outlined circle, outlined pentagon, light gray circle.\n",
      "- Third column: black circle, black hexagon, (missing tile).\n",
      "</step_3>\n",
      "ORIGINAL ITEM: {'id': 3023, 'combined_image_path': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images/center_single/train/3023.png', 'correct_answer': 5, 'subset_split': 'center_single_train'}\n",
      "curr_answer_gt: [5]\n",
      "idx 0\n",
      "STEPS ONLY: [Perception]\n",
      "<step_1>\n",
      "The problem matrix is a 3×3 grid with the bottom right cell missing (the 9th cell labeled as \"?\").\n",
      "</step_1>\n",
      "<step_2>\n",
      "First row (left to right): black circle, light gray circle, black circle.\n",
      "</step_2>\n",
      "<step_3>\n",
      "Second row (left to right): black pentagon, outlined pentagon, black hexagon.\n",
      "</step_3>\n",
      "<step_4>\n",
      "Third row (left to right): dark gray circle, light gray circle, missing tile.\n",
      "</step_4>\n",
      "<step_5>\n",
      "The answer set displays 8 candidate tiles:\n",
      "1. Black circle.\n",
      "2. Light gray circle.\n",
      "3. Black triangle.\n",
      "4. Light gray outlined circle.\n",
      "5. Dark gray circle.\n",
      "6. Medium gray circle.\n",
      "7. Black pentagon.\n",
      "8. Black hexagon.\n",
      "</step_5>\n",
      "\n",
      "[Reasoning]\n",
      "<step_1>\n",
      "Looking at the matrix by shape: all cells in each row have the same shape (Row 1 = circle, Row 2 = pentagon, Row 3 = circle).\n",
      "</step_1>\n",
      "<step_2>\n",
      "Within each row, the color scheme alternates or follows a logic:\n",
      "- Row 1: black circle, light gray outlined circle, black circle (dark-dark-light).\n",
      "- Row 2: black pentagon, outlined pentagon, black hexagon (dark-outline-dark, with a shape change at rightmost position).\n",
      "- Row 3: dark gray circle, light gray circle, (missing tile).\n",
      "</step_2>\n",
      "<step_3>\n",
      "Examining the columns:\n",
      "- First column: black circle, black pentagon, dark gray circle.\n",
      "- Second column: light gray outlined circle, outlined pentagon, light gray circle.\n",
      "- Third column: black circle, black hexagon, (missing tile).\n",
      "</step_3>\n",
      "<step_4>\n",
      "The missing tile needs to be a circle (to match the row’s shapes).\n",
      "</step_4>\n",
      "ORIGINAL ITEM: {'id': 3023, 'combined_image_path': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images/center_single/train/3023.png', 'correct_answer': 5, 'subset_split': 'center_single_train'}\n",
      "curr_answer_gt: [5]\n",
      "idx 0\n",
      "STEPS ONLY: [Perception]\n",
      "<step_1>\n",
      "The problem matrix is a 3×3 grid with the bottom right cell missing (the 9th cell labeled as \"?\").\n",
      "</step_1>\n",
      "<step_2>\n",
      "First row (left to right): black circle, light gray circle, black circle.\n",
      "</step_2>\n",
      "<step_3>\n",
      "Second row (left to right): black pentagon, outlined pentagon, black hexagon.\n",
      "</step_3>\n",
      "<step_4>\n",
      "Third row (left to right): dark gray circle, light gray circle, missing tile.\n",
      "</step_4>\n",
      "<step_5>\n",
      "The answer set displays 8 candidate tiles:\n",
      "1. Black circle.\n",
      "2. Light gray circle.\n",
      "3. Black triangle.\n",
      "4. Light gray outlined circle.\n",
      "5. Dark gray circle.\n",
      "6. Medium gray circle.\n",
      "7. Black pentagon.\n",
      "8. Black hexagon.\n",
      "</step_5>\n",
      "\n",
      "[Reasoning]\n",
      "<step_1>\n",
      "Looking at the matrix by shape: all cells in each row have the same shape (Row 1 = circle, Row 2 = pentagon, Row 3 = circle).\n",
      "</step_1>\n",
      "<step_2>\n",
      "Within each row, the color scheme alternates or follows a logic:\n",
      "- Row 1: black circle, light gray outlined circle, black circle (dark-dark-light).\n",
      "- Row 2: black pentagon, outlined pentagon, black hexagon (dark-outline-dark, with a shape change at rightmost position).\n",
      "- Row 3: dark gray circle, light gray circle, (missing tile).\n",
      "</step_2>\n",
      "<step_3>\n",
      "Examining the columns:\n",
      "- First column: black circle, black pentagon, dark gray circle.\n",
      "- Second column: light gray outlined circle, outlined pentagon, light gray circle.\n",
      "- Third column: black circle, black hexagon, (missing tile).\n",
      "</step_3>\n",
      "<step_4>\n",
      "The missing tile needs to be a circle (to match the row’s shapes).\n",
      "</step_4>\n",
      "<step_5>\n",
      "The color pattern for circles in the third column (top to bottom) is: black (circle), black (hexagon), ?. The first in the row (third row) is dark gray circle, second is light gray circle. This suggests a shade progression from dark gray to light gray, so the third circle could be black, to fit the darkest-lightest-darkest circular progression, consistent with other rows and maintain the sequence.\n",
      "</step_5>\n",
      "ORIGINAL ITEM: {'id': 3023, 'combined_image_path': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images/center_single/train/3023.png', 'correct_answer': 5, 'subset_split': 'center_single_train'}\n",
      "curr_answer_gt: [5]\n",
      "idx 0\n",
      "STEPS ONLY: [Perception]\n",
      "<step_1>\n",
      "The problem matrix is a 3×3 grid with the bottom right cell missing (the 9th cell labeled as \"?\").\n",
      "</step_1>\n",
      "<step_2>\n",
      "First row (left to right): black circle, light gray circle, black circle.\n",
      "</step_2>\n",
      "<step_3>\n",
      "Second row (left to right): black pentagon, outlined pentagon, black hexagon.\n",
      "</step_3>\n",
      "<step_4>\n",
      "Third row (left to right): dark gray circle, light gray circle, missing tile.\n",
      "</step_4>\n",
      "<step_5>\n",
      "The answer set displays 8 candidate tiles:\n",
      "1. Black circle.\n",
      "2. Light gray circle.\n",
      "3. Black triangle.\n",
      "4. Light gray outlined circle.\n",
      "5. Dark gray circle.\n",
      "6. Medium gray circle.\n",
      "7. Black pentagon.\n",
      "8. Black hexagon.\n",
      "</step_5>\n",
      "\n",
      "[Reasoning]\n",
      "<step_1>\n",
      "Looking at the matrix by shape: all cells in each row have the same shape (Row 1 = circle, Row 2 = pentagon, Row 3 = circle).\n",
      "</step_1>\n",
      "<step_2>\n",
      "Within each row, the color scheme alternates or follows a logic:\n",
      "- Row 1: black circle, light gray outlined circle, black circle (dark-dark-light).\n",
      "- Row 2: black pentagon, outlined pentagon, black hexagon (dark-outline-dark, with a shape change at rightmost position).\n",
      "- Row 3: dark gray circle, light gray circle, (missing tile).\n",
      "</step_2>\n",
      "<step_3>\n",
      "Examining the columns:\n",
      "- First column: black circle, black pentagon, dark gray circle.\n",
      "- Second column: light gray outlined circle, outlined pentagon, light gray circle.\n",
      "- Third column: black circle, black hexagon, (missing tile).\n",
      "</step_3>\n",
      "<step_4>\n",
      "The missing tile needs to be a circle (to match the row’s shapes).\n",
      "</step_4>\n",
      "<step_5>\n",
      "The color pattern for circles in the third column (top to bottom) is: black (circle), black (hexagon), ?. The first in the row (third row) is dark gray circle, second is light gray circle. This suggests a shade progression from dark gray to light gray, so the third circle could be black, to fit the darkest-lightest-darkest circular progression, consistent with other rows and maintain the sequence.\n",
      "</step_5>\n",
      "<step_6>\n",
      "Only answer choices 1 and 5 show a circle—1 is black, 5 is dark gray. But 5 matches the first cell of the row, which would break the row’s progression (shouldn’t repeat the same color). Answer 1 fits better, as it provides distinct values across the row and column, and maintains pattern symmetry.\n",
      "</step_6>\n",
      "ORIGINAL ITEM: {'id': 3023, 'combined_image_path': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/RAVEN/processed_raven_images/center_single/train/3023.png', 'correct_answer': 5, 'subset_split': 'center_single_train'}\n",
      "curr_answer_gt: [5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCorrect answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample[\u001b[33m'\u001b[39m\u001b[33mitem\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# Generate process supervision data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     curr_outputs = \u001b[43mbuild_process_supervision\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m=\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnum_return_sequences\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m#     outputs.extend(curr_outputs)\u001b[39;00m\n\u001b[32m     34\u001b[39m \n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m#     # Print first output for debugging\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m \n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# print(f\"\\nGenerated {len(outputs)} rollout samples\")\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mbuild_process_supervision\u001b[39m\u001b[34m(inputs, items, num_return_sequences, args)\u001b[39m\n\u001b[32m      5\u001b[39m response_list = build_responses_azure(\n\u001b[32m      6\u001b[39m     inputs, \n\u001b[32m      7\u001b[39m     num_return_sequences,\n\u001b[32m      8\u001b[39m     max_new_tokens=args.get(\u001b[33m'\u001b[39m\u001b[33mmax_new_tokens\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m4096\u001b[39m),\n\u001b[32m      9\u001b[39m     temperature=args.get(\u001b[33m'\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1.0\u001b[39m)\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mresponses produced by build_process_supervision\u001b[39m\u001b[33m\"\u001b[39m, response_list) \u001b[38;5;66;03m# num_return_sequences = n, so n rollouts for each input image. \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m steps_with_score = \u001b[43mbuild_mc_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mbuild_mc_scores\u001b[39m\u001b[34m(inputs, response_list, items, num_return_sequences, args)\u001b[39m\n\u001b[32m     26\u001b[39m curr_prefixes = []\n\u001b[32m     27\u001b[39m curr_answer_gt = []\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, (flat_steps, flag) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mflat_steps_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_flag\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step_cnt >= \u001b[38;5;28mlen\u001b[39m(flat_steps):\n\u001b[32m     31\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Load and process RAVEN dataset\n",
    "dataset = RAVENDataset(\n",
    "    data=args['prompt_path'],\n",
    "    sample_max_num=args['sample_max_num'],\n",
    "    sample_start_idx=args['sample_start_idx'],\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded: {len(dataset)} samples\")\n",
    "\n",
    "# Process a small batch for demonstration\n",
    "batch_size = args['batch_size']\n",
    "outputs = []\n",
    "\n",
    "for i in range(0, min(len(dataset), batch_size)):\n",
    "    sample = dataset[i]\n",
    "    \n",
    "    # Prepare input for processing\n",
    "    inputs = [(sample['rollout_user_prompt'], sample['image'])]\n",
    "    items = [sample['item']]\n",
    "    \n",
    "    print(f\"\\n[{localtime()}] Processing sample {i+1}/{min(len(dataset), batch_size)}\")\n",
    "    print(f\"Image path: {sample['image_path']}\")\n",
    "    print(f\"Correct answer: {sample['item']['correct_answer']}\")\n",
    "    \n",
    "    # Generate process supervision data\n",
    "    curr_outputs = build_process_supervision(\n",
    "        inputs=inputs,\n",
    "        items=items,\n",
    "        num_return_sequences=args['num_return_sequences'],\n",
    "        args=args\n",
    "    )\n",
    "    \n",
    "#     outputs.extend(curr_outputs)\n",
    "    \n",
    "#     # Print first output for debugging\n",
    "#     if i == 0:\n",
    "#         print(\"\\nFirst sample output:\")\n",
    "#         print_process_supervision(curr_outputs[0])\n",
    "\n",
    "# print(f\"\\nGenerated {len(outputs)} rollout samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outputs to file\n",
    "output_file = os.path.join(args['out_dir'], 'raven_step_by_step_rollouts.jsonl')\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    for output in outputs:\n",
    "        f.write(json.dumps(output) + '\\n')\n",
    "\n",
    "print(f\"Saved {len(outputs)} outputs to {output_file}\")\n",
    "\n",
    "# Display summary statistics\n",
    "total_steps = sum(len(output['steps_with_score']) for output in outputs)\n",
    "avg_steps = total_steps / len(outputs) if outputs else 0\n",
    "avg_score = sum(\n",
    "    sum(step['score'] for step in output['steps_with_score']) / len(output['steps_with_score'])\n",
    "    for output in outputs if output['steps_with_score']\n",
    ") / len(outputs) if outputs else 0\n",
    "\n",
    "print(f\"\\nSummary Statistics:\")\n",
    "print(f\"Total outputs: {len(outputs)}\")\n",
    "print(f\"Average steps per output: {avg_steps:.2f}\")\n",
    "print(f\"Average step score: {avg_score:.3f}\")\n",
    "\n",
    "# Show sample output structure\n",
    "if outputs:\n",
    "    print(f\"\\nSample output keys: {list(outputs[0].keys())}\")\n",
    "    if outputs[0]['steps_with_score']:\n",
    "        print(f\"Sample step keys: {list(outputs[0]['steps_with_score'][0].keys())}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmr_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
